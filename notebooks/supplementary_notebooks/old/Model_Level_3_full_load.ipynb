{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e516e8-c67d-4f27-8353-7f749f2eed0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2022 EY Data Science Challenge\n",
    "## Model Building - Level 3\n",
    "\n",
    "| Challenge | Locations                     | Spatial Res        | Species          | Satellite Data                                                |\n",
    "|-----------|-------------------------------|--------------------|------------------|---------------------------------------------------------------|\n",
    "|1    | Australia                     | Coarse (4km)  | 1 of 23 species  | TerraClimate                                                  |\n",
    "| 2         | Australia, Costa Rica         | Moderate (1km) | 5 of 23 species       | TerraClimate, Sentinel-2                                      |\n",
    "|***3***     | Australia, Costa Rica,<br>Europe | Fine (10m)   | 23 of all species       | TerraClimate, Sentinel-2,<br>Land cover, water extent, elevation |\n",
    "\n",
    "\n",
    "In this notebook, we will demonstrate a complex model workflow that can form a basis for developing a comprehensive solution to the challenge. As specified in the third row of the table above, this model will be trained on three international regions at the finest spatial resolution (10m x 10m), predicting all 23 target species against all available frog occurrence data. The model will be trained with all of the available data sources explored in the supplementary notebooks provided for the challenge, namely [TerraClimate](https://planetarycomputer.microsoft.com/dataset/terraclimate), [Sentinel-2](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a), [Land Cover](https://planetarycomputer.microsoft.com/dataset/group/io-land-cover), [JRC Global Surface Water](https://planetarycomputer.microsoft.com/dataset/jrc-gsw), and [Copernicus Digital Elevation](https://planetarycomputer.microsoft.com/dataset/cop-dem-glo-30). We restrict this analysis to a five year window from the start of 2015 to the end of 2019, and will make the assumption that frog occurrences within that time period are representative of the entire time period (i.e. the frogs take longer than 5 years to move). \n",
    "\n",
    "Most of the functions present in this notebook were adapted from the following notebooks:\n",
    "- [GBIF/Frog](Frogs.ipynb)\n",
    "- [TerraClimate/Weather](Weather.ipynb)\n",
    "- [Sentinel-2](Weather.ipynb)\n",
    "- [Land Cover](Weather.ipynb)\n",
    "- [JRC Global Surface Water](Weather.ipynb)\n",
    "- [Copernicus Digital Elevation](Weather.ipynb)\n",
    "\n",
    "`UPDATE LINKS^`\n",
    "\n",
    "Again, it must be noted that this notebook is just a starting point. We make plenty of assumptions in this notebook that you may not think is best for solving the challenge effectively. You are encouraged to modify these functions, to rewrite them completely, or to try a different approach entirely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652ce4c-c75d-4484-a43a-31ffcf7a2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Image processing\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "# Geospatial\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "from shapely.geometry import Point, Polygon\n",
    "import xarray as xr\n",
    "import rasterio.features\n",
    "import rasterio\n",
    "import rioxarray as rio\n",
    "\n",
    "import fsspec\n",
    "# import xrspatial.multispectral as ms\n",
    "\n",
    "# API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Import Planetary Computer\n",
    "import stackstac\n",
    "import pystac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Folder to store extracted files\n",
    "# storage_path = './penrith_data/'\n",
    "storage_path = './penrith_data/'\n",
    "\n",
    "# Path to data folder with provided material\n",
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c275d03-3828-402e-baa4-f7a4d23c4a3c",
   "metadata": {},
   "source": [
    "### Jupyter Memory\n",
    "\n",
    "For any advanced workflow, it is essential that you have enough memory allocated to Jupyter to facilitate high volume data processing. Often the default memory allocation is quite low, at about 0.5-1GB. Depending on your specific environment, you should follow the relevant documentation online to ensure your notebook environment can handle the large workflows we will be exploring. 10GB of memory should be enough to run this specific demonstration notebook, but we would recommend allocating the majority of your RAM especially when you are collecting and processing your own training and testing data.\n",
    "\n",
    "For the JupyterHub environment that comes with the recommended VM environment for this challenge, this is done by changing the byte allocation in `/etc/jupyterhub/default_jupyter_config.py`. The specific parameter to change is `max_buffer_size` which we have set to 10GB. Additionally, the `iopub_data_rate_limit` is also worth changing if the workflow involves visualising large amounts of data.\n",
    "\n",
    "```\n",
    "c.NotebookApp.max_buffer_size = 10737418240\n",
    "c.NotebookApp.iopub_data_rate_limit = 10737418240\n",
    "```\n",
    "\n",
    "Even with more RAM allocated, the resolution of the satellite data we're working with will quickly become too much for some operations. Hence, a large part of this challenge will come down to designing a memory-efficient model training process. Consider saving processing products to file to avoid re-running processing operations every time. Clear variables with the `del` key if they are no longer in use. Optimise your processing code.\n",
    "\n",
    "Here are some notes on Jupyter and how it handles memory. These may come in handy when troubleshooting\n",
    "\n",
    "- **The kernel will die when it runs out of memory**, without explicitly prompting you that it is a memory issue. If you find you are having to restart your kernel when running a certain cell, it is likely that you have exceeded the memory allocation for Jupyter.\n",
    "\n",
    "- Even if your code is memory-optimised and is not saving large datasets to variable names, sometimes Jupyter contains hidden pointers to these objects which can hog memory. For this reason, it is sometimes necessary to **restart the kernel after large processing operations** and load in the resultant data from file. This should free up any stranded memory.\n",
    "\n",
    "\n",
    "To monitor the kernel's memory usage, consider using commands such as `htop` in the VM's terminal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ef421-3dea-4894-a605-d1695657335b",
   "metadata": {},
   "source": [
    "### Gathering Frog Data\n",
    "\n",
    "For this demonstration, we will constrain our search to frogs in the Greater Sydney area. This gives a varied landscape of bushland, plains, rivers, and urban areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75a397-ae04-48ae-89bd-406a209be3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greater Sydney, NSW\n",
    "# region_name = 'Greater Sydney, NSW'\n",
    "# min_lon, min_lat = (150.25, -34.15)  # Lower-left corner\n",
    "# max_lon, max_lat = (151.05, -33.35)  # Upper-right corner\n",
    "\n",
    "# Penrith, NSW\n",
    "region_name = 'Penrith, NSW'\n",
    "min_lon, min_lat = (150.50, -34.10)  # Lower-left corner\n",
    "max_lon, max_lat = (150.80, -33.40)  # Upper-right corner\n",
    "\n",
    "# region_name = 'Sydney, NSW'\n",
    "# min_lon, min_lat = (151.20, -33.70)  # Lower-left corner\n",
    "# max_lon, max_lat = (151.35, -33.60)  # Upper-right corner\n",
    "\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# Plot map of region\n",
    "crs = {'init':'epsg:4326'}\n",
    "fig, ax = plt.subplots(figsize = (7, 7))\n",
    "ax.scatter(x=[min_lon, max_lon], y=[min_lat, max_lat], alpha=0)\n",
    "cx.add_basemap(ax, crs=crs)\n",
    "ax.set_title(region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bba6da-6e94-4b01-ae6f-90dab7af487e",
   "metadata": {},
   "source": [
    "#### Fetching Frog Response Variable\n",
    "Before we can build our model, we need to query the GBIF API to obtain the frog occurrence data for our region. If you have not checked out the [frog notebook](Frogs.ipynb) yet, we recommend you do before moving on so you can better understand the following functions. The code from that notebook is wrapped up in the `get_frogs` function defined below. This function will obtain all frog occurrences for the given region in the five years from the start of 2015 to the end of 2019. It returns a geopandas dataframe of each occurrence, its species, and its latitude and longitude coordinates. The challenge is to predict the habitats of the 23 species specified in the ['australian_frogs.csv'](australian_frogs.csv) file. Note that not all 23 will be present for a given area.\n",
    "\n",
    "We will take all frog species to start, and will flag the 23 species of importance later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa92e9-714c-4868-8b37-c9d7d0813359",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def get_frogs(bbox, query_params, crs = {'init':'epsg:4326'}, orderKey=\"952\", verbose=False):\n",
    "    \"\"\"Returns the dataframe of all frog occurrences for the bounding box specified.\"\"\"\n",
    "\n",
    "    # Set query parameters\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    limit = 300\n",
    "    offset = 0\n",
    "    parameters = {\n",
    "        **query_params,\n",
    "        \"orderKey\":orderKey, # The order Anura (frogs) is indicated by key 952\n",
    "        \"decimalLatitude\":f\"{min_lat},{max_lat}\", # Latitude range\n",
    "        \"decimalLongitude\":f\"{min_lon},{max_lon}\", # Longitude range\n",
    "        \"limit\":limit,\n",
    "        \"offset\":offset\n",
    "    }\n",
    "\n",
    "    # Query API\n",
    "    frogs = pd.DataFrame()\n",
    "    while True:\n",
    "        # Fetch results\n",
    "        parameters['offset'] = offset\n",
    "        response = requests.get(\"https://api.gbif.org/v1/occurrence/search\", params = parameters).json()\n",
    "        total = response['count']\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"{offset} of {total}\") if verbose else None\n",
    "\n",
    "        # Add results to dataframe\n",
    "        frogs = frogs.append(\n",
    "            pd.DataFrame(response['results'])\n",
    "            [[\"decimalLatitude\", \"decimalLongitude\", \"species\", \"speciesKey\"]]\n",
    "        )\n",
    "        if response['endOfRecords']:\n",
    "            break\n",
    "        offset += limit\n",
    "\n",
    "    geo_frogs = gpd.GeoDataFrame(\n",
    "        frogs.reset_index(drop=True), \n",
    "        geometry=gpd.points_from_xy(frogs.decimalLongitude, frogs.decimalLatitude),\n",
    "        crs=crs\n",
    "    )\n",
    "    return geo_frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056b941-0caf-404b-8686-c0caff33a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the date range to the GBIF API\n",
    "gbif_api_params = {\"year\":\"2015,2019\"}\n",
    "\n",
    "# Get frogs!\n",
    "# all_frog_data = get_frogs(bbox, gbif_api_params, verbose=True)\n",
    "# all_frog_data.to_csv(storage_path+'all_frogs_Sydney_2015_2019.csv', index=None)\n",
    "# all_frog_data = pd.read_csv(storage_path+'all_frogs_Sydney_2015_2019.csv')\n",
    "\n",
    "all_frog_data = get_frogs(bbox, gbif_api_params, verbose=True)\n",
    "all_frog_data.to_csv(storage_path+'all_frogs_Penrith_2015_2019.csv', index=None)\n",
    "all_frog_data = pd.read_csv(storage_path+'all_frogs_Penrith_2015_2019.csv')\n",
    "\n",
    "all_frog_data.sample(10, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241eaf4-d698-4bd5-aadc-d885877686fd",
   "metadata": {},
   "source": [
    "Now we need to specify the response variable for our model. This will be the species name if it is one of the 23 species of interest, and 'other' if otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca6188-fc9e-409e-acdc-04ac4e7bf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in species data\n",
    "frog_species = pd.read_csv(data_path+'australian_frogs.csv')\n",
    "\n",
    "# Create response variable\n",
    "frog_data = (\n",
    "    all_frog_data\n",
    "    # Convert species key to integer\n",
    "    .assign(\n",
    "        speciesKey = lambda x: np.where(x.speciesKey.isna(), 0, x.speciesKey).astype(int)\n",
    "    )\n",
    "    .merge(\n",
    "        frog_species[['speciesKey', 'species']],\n",
    "        on='speciesKey',\n",
    "        how='left'\n",
    "    )\n",
    "    .assign(\n",
    "        species = lambda x: np.where(x.species_y.isna(), 'Other', x.species_y)\n",
    "    )\n",
    "    .drop(['species_x', 'species_y'], 1)\n",
    ")\n",
    "frog_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb23a16-771f-47af-be29-a574bc8926d2",
   "metadata": {},
   "source": [
    "Below, we can visualise the frog species distribution of the area. Here, only seven of the 23 are present and crinia signifera, the common eastern froglet, is the most common species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5f274-609a-4075-9992-d8ecf7e3e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize = (10, 12), gridspec_kw={'height_ratios':[0.7, 0.3]})\n",
    "\n",
    "# Bar chart\n",
    "bar_data = frog_data.species.value_counts()\n",
    "barchart = ax[1].bar(bar_data.index.str.replace(' ', '\\n'), bar_data)\n",
    "\n",
    "# Colour cycle to ensure colors match in both plots\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "for i, color in zip(range(len(bar_data)), prop_cycle):\n",
    "    species_name = bar_data.index[i]\n",
    "    barchart[i].set_color(color['color'])\n",
    "    barchart[i].set_label(f\"{species_name}\\nCount: {bar_data[i]}\")\n",
    "    filt = frog_data.species == species_name\n",
    "    # Scatter plot\n",
    "    ax[0].scatter(frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude, marker='.', color=color['color'])\n",
    "\n",
    "# Add other features\n",
    "ax[0].set_title(f\"Frog occurrences for {region_name}\")\n",
    "ax[1].set_title(f\"Frog species distribution\\nin {region_name}\")\n",
    "cx.add_basemap(ax[0], crs=crs, alpha=0.5) # Add basemap\n",
    "plt.xticks(rotation=45)\n",
    "fig.legend(loc=(0.70, 0.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4e031-92b1-476f-9a8e-780b6fd48022",
   "metadata": {},
   "source": [
    "### Pseudo-absence\n",
    "\n",
    "The scatterplot above shows how frog occurrences are heavily biased around urban areas, where people are more likely to come across them. They also cluster tightly around towns, parks, bush trails etc. This is one issue that would be worth addressing to maximise success in this challenge. \n",
    "\n",
    "One method of addressing the sampling bias inherent in the database is to focus on predicting each species, and to use the occurrence points of other species as absence points. This way, if a different species of frog has been sighted in a specific location, we can be more certain that the species we are trying to predict is not at that same location. Alternatively, if we just picked a random point where there are no frog occurrences, we cannot be certain that frogs are not in that location. It might just be that there are no walking tracks near that location, and therefore the frogs would not show up in our database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1145151d-0eed-417a-a6e4-fbec12447ba0",
   "metadata": {},
   "source": [
    "### Class Balancing\n",
    "\n",
    "Another issue shown clealy in the barchart is the class imbalance of the frog species. Of the 23 species, only seven of them are present in this area for the given time window, and three of the seven have less than 20 observations. For this demonstration, we will drop these three species, down sample the 'Other' class, and up-sample each of the minority classes to match that of crinia signifera. This is quite a naive approach, so you are encouraged to pursue other more thoughtful ways of addressing this issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af6081-3662-4996-be81-e83be14b454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = bar_data[1]\n",
    "\n",
    "balanced_frogs = pd.DataFrame()\n",
    "\n",
    "for species, counts in zip(bar_data.index[0:5], bar_data[0:5]):\n",
    "    print(species)\n",
    "    balanced_frogs = balanced_frogs.append(\n",
    "        frog_data\n",
    "        [lambda x: x.species == species]\n",
    "        .sample(target_counts, random_state=420, replace=True)\n",
    "    )\n",
    "\n",
    "# Assign index as key\n",
    "balanced_frogs = balanced_frogs.reset_index(drop=True).assign(key=lambda x: x.index)\n",
    "    \n",
    "balanced_frogs.species.value_counts().plot(kind='bar', title='Frog Species After Balancing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa63520-8c54-44d5-865d-cecd315df19f",
   "metadata": {},
   "source": [
    "After balancing the classes, we finally have our training data visualised below. Again, it must be stressed that this is just one way of addressing the sampling bias inherent in the GBIF data and it does not address the bias completely. Since we will be using this training dataset for evaluation, the evaluation metrics will also contain bias. You are encouraged to improve the training set collection process, particularly the frog absence sampling, until you are confident in its ability to accurately train and evaluate your model. For now, we will continue with this training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34ea4d-6c52-4ca4-95cd-f7c8d5a05b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "for species in balanced_frogs.species.unique():\n",
    "    filt = balanced_frogs.species == species\n",
    "    ax.scatter(balanced_frogs[filt].decimalLongitude, balanced_frogs[filt].decimalLatitude,\n",
    "        label=species, marker='.', alpha=0.25)\n",
    "\n",
    "ax.legend()\n",
    "cx.add_basemap(ax, crs=crs, alpha=0.5)\n",
    "ax.set_title(f\"Training set for {region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da66d0-f4ae-49b9-96aa-8f09f3e174c6",
   "metadata": {},
   "source": [
    "### Fetching predictor variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320ece8-26ad-4aee-afcc-b3ac1d58f7ef",
   "metadata": {},
   "source": [
    "To assist with performance, we will store predictor variables in geotiff files with the `save_to_geotiff` function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40311b-e2c2-49c0-b791-71f1e2962746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_geotiff(arr, filename, bbox, dtype='uint16'):\n",
    "    # If filename is specified, save mosaic to geotiff  \n",
    "    bands = arr.shape[0]\n",
    "    height = arr.shape[1]\n",
    "    width = arr.shape[2]\n",
    "    print(arr.shape)\n",
    "        \n",
    "    # write bandnames to separate file\n",
    "    with open(filename+'.bands', 'w') as file:\n",
    "        file.write(','.join(arr.band.values))\n",
    "        \n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    # Define the Coordinate Reference System (CRS) to be common Lat-Lon coordinates\n",
    "    # Define the tranformation using our bounding box so the Lat-Lon information is written to the GeoTIFF\n",
    "    gt = rasterio.transform.from_bounds(min_lon, min_lat, max_lon, max_lat, width, height)\n",
    "    arr.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    arr.rio.write_transform(transform=gt, inplace=True);\n",
    "    \n",
    "    # Create the GeoTIFF output file using the defined parameters\n",
    "    with rasterio.open(filename+'.tiff', 'w', driver='GTiff', width=width, height=height, crs='epsg:4326',\n",
    "                       transform=gt, count=bands, compress='lzw', dtype=dtype) as dst:\n",
    "        for band in range(bands):\n",
    "            print(f'writing {band+1} of {bands}')\n",
    "            dst.write(arr[band],band+1)\n",
    "        dst.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd4236-b9a9-4622-9a59-2a3365ae9a01",
   "metadata": {},
   "source": [
    "#### TerraClimate\n",
    "\n",
    "To get the TerraClimate data, we write a function called `get_terraclimate`. This function will fetch all data intersecting with the bounding box and will calculate various metrics over the time dimension for each coordinate. In this example, we will take six metrics from four assets, namely the mean and overall maximum monthly air temp (`tmax_mean`, `tmax_max`), mean and overall minimum monthly air temp (`tmin_mean`, `tmin_min`), mean accumulated precipitation (`ppt_mean`) and mean soil moisture (`soil_mean`), all calculated over a five year timeframe from the start of 2015 to the end of 2019.\n",
    "\n",
    "Because the TerraClimate data has a comparitively lower spatial resolution to the other satellite data, we will need to interpolate this data to match the higher resolution data. To achieve this, the `get_terraclimate` function has an interpolation functionality which will allow the comparitively coarse temporal resolution of the terraclimate data to be mapped to a larger set of coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f4351-847a-4c66-a764-f9a0888b9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terraclimate(bbox, filename=None, metrics={'mean':{'fn':np.nanmean,'params':{}}}, time_slice=None, assets=None, features=None, interp_dims=None, verbose=True):\n",
    "    \"\"\"Returns terraclimate metrics for a given area (or None if filename specified), allowing results to be interpolated onto a larger image.\n",
    "    \n",
    "    Attributes:\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    filename -- string or None. If None, will save result to geotiff. \n",
    "    metrics -- Nested dictionary in the form {<metric_name>:{'fn':<metric_function>,'params':<metric_kwargs_dict>}, ... }\n",
    "    time_slice -- Tuple of datetime strings to select data between, e.g. ('2015-01-01','2019-12-31')\n",
    "    assets -- list of terraclimate assets to take\n",
    "    features -- list of asset metrics to take, specified by strings in the form '<asset_name>_<metric_name>'\n",
    "    interp_dims -- Tuple of dimensions (n, m) to interpolate results to\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    collection = pystac.read_file(\"https://planetarycomputer.microsoft.com/api/stac/v1/collections/terraclimate\")\n",
    "    asset = collection.assets[\"zarr-https\"]\n",
    "    store = fsspec.get_mapper(asset.href)\n",
    "    data = xr.open_zarr(store, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    \n",
    "    # Select datapoints that overlap region\n",
    "    if time_slice is not None:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat),time=slice(time_slice[0],time_slice[1]))\n",
    "    else:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat))\n",
    "    if assets is not None:\n",
    "        data = data[assets]\n",
    "    print('Loading data') if verbose else None\n",
    "    data = data.rename(lat='y', lon='x').to_array().compute()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    combined_values = []\n",
    "    combined_bands = []\n",
    "    for name, metric in metrics.items():\n",
    "        print(f'Calculating {name}') if verbose else None\n",
    "        sum_data = xr.apply_ufunc(\n",
    "            metric['fn'], data, input_core_dims=[[\"time\"]], kwargs=metric['params'], dask = 'allowed', vectorize = True\n",
    "        ).rename(variable='band')\n",
    "        xcoords = sum_data.x\n",
    "        ycoords = sum_data.y\n",
    "        dims = sum_data.dims\n",
    "        combined_values.append(sum_data.values)\n",
    "        for band in sum_data.band.values:\n",
    "            combined_bands.append(band+'_'+name)\n",
    "        \n",
    "    # Combine metrics\n",
    "    combined_values = np.concatenate(\n",
    "        combined_values,\n",
    "        axis=0\n",
    "    )\n",
    "    combined_data = xr.DataArray(\n",
    "        data=combined_values,\n",
    "        dims=dims,\n",
    "        coords=dict(\n",
    "            band=combined_bands,\n",
    "            y=ycoords,\n",
    "            x=xcoords\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    # Take relevant bands:\n",
    "    combined_data = combined_data.sel(band=features)\n",
    "    \n",
    "    if interp_dims is not None:\n",
    "        print(f'Interpolating image') if verbose else None\n",
    "        interp_coords = (np.linspace(bbox[0], bbox[2], interp_dims[0]), np.linspace(bbox[1], bbox[3], interp_dims[1]))\n",
    "        combined_data = combined_data.interp(x=interp_coords[0], y=interp_coords[1], method='nearest', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "        \n",
    "    if filename is not None:\n",
    "        save_to_geotiff(combined_data, filename, bbox)\n",
    "        return None\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae14daa-86ed-4d10-b483-4a71e6d3db13",
   "metadata": {},
   "source": [
    "Next, we write a function called `get_pc` that will assist us in grabbing each predictor variable from the planetary computer. It will calculate the median mosaic and return it as an xarray object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0aab8-840d-4169-baa8-ed2367e9e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to access the planetary computer\n",
    "def get_pc(product, bbox, dims=None, assets={\"image/tiff\"}, resolution=10, pc_query=None, date_range=None, na_val=None, filename=None):\n",
    "    \"\"\"Return the median mosaic xarray of a specified planetary computer product for a given location\n",
    "    \n",
    "    Attributes:\n",
    "    product -- string representing the planetary computer product\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    assets -- list of assets to take from the product\n",
    "    resolution -- resolution in meters\n",
    "    pc_query -- dictionary of arguments to pass to the planetary computer\n",
    "    date_range -- string representing the date range of the query e.g. '2020-01-01/2020-12-31'\n",
    "    na_val -- the value representing na values in the dataset. Will be ignored in median calculation\n",
    "    filename -- string or None. If None, will save result to geotiff.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query the planetary computer\n",
    "    stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "    search = stac.search(\n",
    "        bbox=bbox,\n",
    "        datetime=date_range,\n",
    "        collections=[product],\n",
    "        limit=500,  # fetch items in batches of 500\n",
    "        query=pc_query\n",
    "    )\n",
    "    items = list(search.get_items())\n",
    "    print('This is the number of scenes that touch our region:',len(items))\n",
    "    signed_items = [planetary_computer.sign(item).to_dict() for item in items]\n",
    "\n",
    "    # Define the scale according to our selected crs, so we will use degrees\n",
    "    scale = resolution / 111320.0 # degrees per pixel for crs=4326 \n",
    "        \n",
    "    # Stack up the items returned from the planetary computer\n",
    "    data = (\n",
    "        stackstac.stack(\n",
    "            signed_items,\n",
    "            epsg=4326, # Use common Lat-Lon coordinates\n",
    "            resolution=scale, # Use degrees for crs=4326\n",
    "            bounds_latlon = bbox,\n",
    "            resampling=rasterio.enums.Resampling.average, # Average resampling method (only required when resolution >10)\n",
    "            chunksize=4096,\n",
    "            assets=assets\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if dims is not None:\n",
    "        print((data.shape[3], data.shape[2]))\n",
    "        if dims[0] != data.shape[3] or dims[1] != data.shape[2]:\n",
    "            print(f\"interp_dims not correct. PC returned dims of {(data.shape[3], data.shape[2])}, not {dims}\")\n",
    "    \n",
    "    if na_val is not None:\n",
    "        data = data.where(lambda x: x != na_val, other=np.nan)\n",
    "    \n",
    "    # Median Composite\n",
    "    median = data.median(dim=\"time\", skipna=True)\n",
    "    \n",
    "    # Rename bands of those with only one band (which otherwise defaults to generic 'data')\n",
    "    if median.shape[0] == 1:\n",
    "        median = median.assign_coords(band=[product])\n",
    "    \n",
    "    if filename is not None:\n",
    "        save_to_geotiff(median, filename, bbox)\n",
    "        return None\n",
    "    \n",
    "    return median.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2c9de-e5ee-44c0-af2d-a2fcc3d99753",
   "metadata": {},
   "source": [
    "The elevation data is the only dataset we are going to pull from the planetary computer that has a spatial resolution greater than 10m, it being 30m. Luckily, the `stackstac.stack` function has interpolation built into it, so all planetary computer products will be returned with the same dimensions. \n",
    "\n",
    "Additionally, we will calculate the slope from the elevation data. To do this, we define the `slope_pct` function to apply over the elevation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdbc1e8-9063-4eb7-a22d-9cc2442e4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_pct(dem, resolution):\n",
    "    # Kernel for rate of elevation change in x-axis.\n",
    "    dx_kernel = np.array([[1, 0, -1],\n",
    "                          [2, 0, -2],\n",
    "                          [1, 0, -1]])\n",
    "    # Kernel for rate of elevation change in y-axis.\n",
    "    dy_kernel = np.array([[1, 2, 1],\n",
    "                          [0, 0, 0],\n",
    "                          [-1, -2, -1]])\n",
    "    # Rate of change calculations for each axis.\n",
    "    dx = convolve(dem, dx_kernel) / (8 * resolution)\n",
    "    dy = convolve(dem, dy_kernel) / (8 * resolution)\n",
    "    # Return rise/run * 100 for slope percent.\n",
    "    return np.sqrt(np.square(dx) + np.square(dy)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7da9ea-10ed-418e-a803-ea4db74e0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictor_datasets(products, bbox, path, interp_dims=(512, 512), product_names={\"cop-dem-glo-30\":'elevation', \"io-lulc\":'landcover', 'jrc-gsw':'surface_water', 'sentinel-2-l2a':'sentinel-2'}):\n",
    "    \"\"\"collect and download all products\"\"\"\n",
    "    for i, (product, params) in enumerate(products.items()):\n",
    "        print(f'loading {product}')\n",
    "        \n",
    "        # Interpolate the weather data to 10m resolution\n",
    "        if product == 'terraclimate':\n",
    "            get_terraclimate(bbox, filename=path+product, interp_dims=interp_dims, **params)\n",
    "        elif product == 'cop-dem-glo-30':\n",
    "            # Don't specify filename so that the array is returned and we can calculate the slope\n",
    "            data = get_pc(product, bbox, dims=interp_dims, **params)\n",
    "        else:\n",
    "            get_pc(product, bbox, dims=interp_dims, filename=path+product, **params)\n",
    "\n",
    "        # Calculate the gradient of the elevation data\n",
    "        if product == 'cop-dem-glo-30':\n",
    "            data_elevation = data.squeeze().drop(\"band\")\n",
    "            slope_vals = slope_pct(data_elevation, products[product]['resolution'])\n",
    "            data_slope = xr.DataArray(\n",
    "                np.expand_dims(slope_vals, 0),\n",
    "                coords=dict(\n",
    "                    band=['gradient'],\n",
    "                    y=data_elevation.y,\n",
    "                    x=data_elevation.x\n",
    "                )\n",
    "            )\n",
    "            save_to_geotiff(data, path+product, bbox)\n",
    "            save_to_geotiff(data_slope, path+product+'_slope', bbox)\n",
    "            \n",
    "            # remove elevation data from memory\n",
    "            del data, data_slope, data_elevation, slope_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03e684-1e8e-453e-9bc5-fd82950cbff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define products and query parameters for the planetary computer\n",
    "products = {\n",
    "    # Elevation\n",
    "    \"cop-dem-glo-30\":{\n",
    "        \"resolution\":10\n",
    "    },\n",
    "    # Land Cover\n",
    "    \"io-lulc\":{\n",
    "        \"resolution\":10\n",
    "    },\n",
    "    # Water extent data\n",
    "    'jrc-gsw':{\n",
    "        \"resolution\":10\n",
    "    },\n",
    "    # Sentinel-2 Spectral Band data\n",
    "    'sentinel-2-l2a':{\n",
    "        \"resolution\":10,\n",
    "        'assets':[\"B04\", \"B03\", \"B02\", \"B08\"],\n",
    "        'pc_query':{\"eo:cloud_cover\": {\"lt\": 0.1}}, # Restrict to only the clearest images (otherwise takes too long to load).\n",
    "        'date_range':'2015-01-01/2019-12-31',\n",
    "        'na_val':0\n",
    "    },\n",
    "    # Weather - might need to adjust x_dim, y_dim params to match dimensions of dataarrays above. Off by one errors common.\n",
    "    \"terraclimate\":{\n",
    "        'metrics':{\n",
    "            'mean':{\n",
    "                'fn':np.nanmean,\n",
    "                'params':{}\n",
    "            },\n",
    "            'min':{\n",
    "                'fn':np.nanmin,\n",
    "                'params':{}\n",
    "            },\n",
    "            'max':{\n",
    "                'fn':np.nanmax,\n",
    "                'params':{}\n",
    "            }\n",
    "        },\n",
    "        'time_slice':('2015-01-01','2019-12-31'),\n",
    "        'assets':['tmax', 'tmin', 'ppt', 'soil'],\n",
    "        'features':['tmax_max', 'tmax_mean', 'tmin_min', 'tmin_mean', 'ppt_mean', 'soil_mean']\n",
    "    }\n",
    "}\n",
    "\n",
    "# convert degrees to pixels for crs=4326 \n",
    "x_dim = int((max_lon - min_lon)*111320.0/10 + 2)\n",
    "y_dim = int((max_lat - min_lat)*111320.0/10 + 1)  \n",
    "\n",
    "print(x_dim, y_dim)\n",
    "\n",
    "save_predictor_datasets(products, bbox, storage_path, interp_dims=(x_dim, y_dim))\n",
    "\n",
    "# Run garbage collector to clear as much memory as possible\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6767b-1c27-4abb-9003-64509d6a1ca5",
   "metadata": {},
   "source": [
    "#### Restart kernel!\n",
    "\n",
    "It is recommended that you restart the Jupyter kernel after writing all data to files using the functions above. This is because Jupyter has memory leak issues that make garbage collection to clear RAM difficult. To free up space, restart the kernel and run all relevant cells except the extraction code above, then read in the files with the code below to continue your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea5801-6f5d-4f3d-8d6e-68770ceef9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_mapper = {\n",
    "    1:'water', 2:'trees', 3:'grass',\n",
    "    4:'flooded_vegetation', 5:'crops',\n",
    "    6:'scrub', 7:'urban', 8:'bare_soil',\n",
    "    9:'snow_ice', 10:'clouds'\n",
    "}\n",
    "\n",
    "\n",
    "all_datasets = []\n",
    "all_bands = []\n",
    "for file in products.keys():\n",
    "    \n",
    "    # Get bands\n",
    "    with open(storage_path+file+'.bands', 'r') as band_file:\n",
    "        bands = band_file.readline().split(',')\n",
    "    \n",
    "    # Make separate masks for io-lulc landcover (one-hot encoding)\n",
    "    if file == 'io-lulc':\n",
    "        for i in range(1, 11):\n",
    "            all_datasets.append(xr.open_rasterio(storage_path+file+'.tiff').assign_coords(band=[landcover_mapper[i]]) == i)\n",
    "            all_bands.append(landcover_mapper[i])\n",
    "    if file == 'cop-dem-glo-30':\n",
    "        all_datasets.append(\n",
    "            xr.open_rasterio(storage_path+file+'.tiff').assign_coords(band=['elevation'])\n",
    "        )\n",
    "        all_bands.append(\"elevation\")\n",
    "        all_datasets.append(\n",
    "            xr.open_rasterio(storage_path+file+'_slope.tiff').assign_coords(band=['slope'])\n",
    "        )\n",
    "        all_bands.append('slope')\n",
    "    else:\n",
    "        all_datasets.append(\n",
    "            xr.open_rasterio(storage_path+file+'.tiff').assign_coords(band=bands)\n",
    "        )\n",
    "        all_bands.extend(bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8531886-a1bd-4b79-8edc-c869ae4b3030",
   "metadata": {},
   "source": [
    "#### Stitching together all predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00d783-349f-4276-976c-f68a95419144",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_geotiff(\n",
    "    xr.concat(all_datasets, dim=\"band\"), \n",
    "    storage_path+'predictors', bbox\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1c9a7-ae33-483f-bfd7-47c43444c66b",
   "metadata": {},
   "source": [
    "### Restart Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14266842-ca6a-46d8-9c68-e657d0f8c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bands\n",
    "with open(storage_path+'predictors.bands', 'r') as band_file:\n",
    "    all_bands = band_file.readline().split(',')\n",
    "\n",
    "predictor_image = xr.open_rasterio(storage_path+'predictors.tiff').assign_coords(band=all_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2e8af-5a84-4c8b-a84a-324365259d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0774bc5-4dff-4812-a1c6-70768abca0c9",
   "metadata": {},
   "source": [
    "##### Joining Features to Response Variable\n",
    "\n",
    "Now that we have read in both our response and predictor variables, we now need to join them onto the response variable of frogs. To do this, we loop through the frog occurrence data and assign each frog occurrence the closest predictor pixel value from each of the predictor variables based on the geo-coordinates. The `sel` method of the xarray dataarray comes in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ac1e6-ff3d-41b3-a0ba-5da2acd2e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_features(model_data, predictor_image):\n",
    "    \"\"\"Joins the features from each feature dataset onto each response variable. \n",
    "\n",
    "    Arguments:\n",
    "    model_data -- dataframe containing the response variable along with [\"decimalLongitude\", \"decimalLatitude\", \"key\"]\n",
    "    all_datasets -- list of feature datasets stored as xarray dataarrays, indexed with geocoordinates\n",
    "    \"\"\"\n",
    "    # For each latitude and longitude coordinate, find the nearest predictor variable pixel values\n",
    "    data_per_point = pd.DataFrame()\n",
    "    for j, (lon, lat, key) in enumerate(zip(model_data.decimalLongitude, model_data.decimalLatitude, model_data.key)):\n",
    "        # Print out some progress markers\n",
    "        if (j+1)%500==0:\n",
    "            print(f\"{j+1} of {len(model_data)}\")\n",
    "\n",
    "        # Get the predictor pixel at the site of the frog occurrence\n",
    "        nearest_point = predictor_image.sel(x=lon, y=lat, method=\"nearest\")\n",
    "\n",
    "        # Prepare values and columns and save them in a dataframe, saving the join key for later reference\n",
    "        values = np.concatenate((np.squeeze(nearest_point.values), np.array([key])))\n",
    "        columns = list(nearest_point.band.values) + ['key']\n",
    "        data_per_point = data_per_point.append(\n",
    "            pd.DataFrame(\n",
    "                np.array([values]), \n",
    "                columns=columns\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Join the predictor variables we just collected back onto the frog data\n",
    "    model_data = model_data.merge(\n",
    "        data_per_point,\n",
    "        on = ['key'],\n",
    "        how = 'inner'\n",
    "    )\n",
    "        \n",
    "    return model_data\n",
    "\n",
    "model_data = join_features(balanced_frogs, predictor_image)\n",
    "\n",
    "gc.collect()\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb154fe-e72c-4e0f-b4ea-5a20384de3f5",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "\n",
    "Now that we have the data in a format appropriate for machine learning, we can begin training a model. For this demonstration notebook, we will use a basic logistic regression model from the [scikit-learn](https://scikit-learn.org/stable/) library. This library offers a wide range of other models, each with the capacity for extensive parameter tuning and customisation capabilities.\n",
    "\n",
    "Scikit-learn models require separation of predictor variables and the response variable. We store the predictor variables in dataframe `X` and the response in the array `y`. We must make sure to drop the response variable from `X`, otherwise the model will have the answers! It also doesn't make sense to use latitude and longitude as predictor variables in such a confined area, so we drop those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dd94e-ba93-4667-897b-3923d3712567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "full_model = LogisticRegression()\n",
    "# Separate the predictor variables from the response\n",
    "X = (\n",
    "    model_data\n",
    "    .drop([\"decimalLatitude\", \"decimalLongitude\", \"speciesKey\", \"occurrenceStatus\", \"geometry\", \"species\", \"key\"], 1)\n",
    ")\n",
    "y = model_data.species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb6222-b558-4314-bf1f-2b64dfd9d3dd",
   "metadata": {},
   "source": [
    "For now, we will train the model using all of our training data. Hence, this section will only reflect the in-sample performance of our model, and not the out-of-sample performance. Out-of-sample performance is crucial in estimating how a model will perform in a real world environment. We will attempt to evaluate the out-of-sample performance of this model in a later section, but for now we can have some fun visualising the in-sample performance for Richmond, NSW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15029b33-daf5-4c4b-8099-de434c74600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51835e-6061-4db0-9ad1-3a2510c6b271",
   "metadata": {},
   "source": [
    "#### Model Prediction\n",
    "\n",
    "Logistic regression is a machine learning model that estimates the probability of a binary response variable. In our case, the model will output the probability of a frog being present at a given location. To visualise this, we need to understand that each pixel on our satellite image has an associated $k$ dimensional vector of predictor variable values, in this case $k=13$ bands relating to elevation data, landcover, JRC water extent, and Sentinel-2 data. Thus, we can associate a $k$ band image with any satellite image. For each of those $k$ band pixels, we can use our logistic regression model to output the probability of a frog being found there. Finally, we can visualise this as a heatmap which will show regions that our model thinks are likely frog habitats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca1d86-7823-4f13-bb8b-b6ae006592a6",
   "metadata": {},
   "source": [
    "##### Heat Map\n",
    "Above, we stitched together each predictor variable into a $k$ band image using the `create_predictor_image` function. Now, we will define another function called `predict_frogs` that will take this image in, along with our logistic regression model, and output the probabilities for each pixel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e9652-9c1a-4a9d-a5a6-f1b705875fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frogs(predictor_image, model):\n",
    "    \"\"\"Returns a (1, n, m) xarray where each pixel value corresponds to the probability of a frog occurrence.\n",
    "    \n",
    "    Takes in the multi-band image outputted by the `create_predictor_image` function as well as the\n",
    "    trained model and returns the predictions for each pixel value. Firstly, the $x$ and $y$ indexes\n",
    "    in the predictor image are stacked into one multi-index $z=(x, y)$ to produce an $k\\times n$\n",
    "    array, which is the format required to feed into our logistic regression model. Then, the array\n",
    "    is fed into the model, returning the model's predictions for the frog likelihood at each pixel. \n",
    "    The predicted probabilities are then indexed by the same multi-index $z$ as before, which allows \n",
    "    the array to be unstacked and returned as a one-band image, ready for plotting.\n",
    "\n",
    "    Arguments:\n",
    "    predictor_image -- (K, n, m) xarray, where K is the number of predictor variables.\n",
    "    model -- sklearn model with K predictor variables.\n",
    "    \"\"\"\n",
    "    # Stack up pixels so they are in the appropriate format for the model\n",
    "    print('stack')\n",
    "    predictor_image = predictor_image.stack(z=(\"y\", \"x\")).transpose()\n",
    "    print('stack')\n",
    "    \n",
    "    # Calculate probability for each pixel point \n",
    "    print('prob')\n",
    "    probabilities = model.predict_proba(\n",
    "        predictor_image\n",
    "    )\n",
    "    print('prob')\n",
    "\n",
    "    \n",
    "    # Just take probability of frog (class=1)\n",
    "    # probabilities = probabilities[:,1]\n",
    "\n",
    "    # Add the coordinates to the probabilities, saving them in an xarray\n",
    "    print('xr')\n",
    "    resultant_image = xr.DataArray(\n",
    "        data=probabilities,\n",
    "        dims=['z', 'band'],\n",
    "        coords=dict(\n",
    "            z=predictor_image.z,\n",
    "            band=model.classes_\n",
    "        )\n",
    "    )\n",
    "    print('xr')\n",
    "    \n",
    "    # Unstack the image\n",
    "    print('unstack')\n",
    "    resultant_image = resultant_image.unstack()\n",
    "    print('unstack')\n",
    "    return resultant_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be5006-f0a6-4bf3-9301-23608fcf5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability for each pixel point \n",
    "resultant_image = predict_frogs(predictor_image, full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bbd7b-4f6b-4e17-a458-ecebfb9d54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_geotiff(\n",
    "    resultant_image.astype('float32'), \n",
    "    storage_path+'results', bbox, dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7045fd-9a68-441a-929d-406a064f8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bands\n",
    "with open(storage_path+'results.bands', 'r') as band_file:\n",
    "    pred_bands = band_file.readline().split(',')\n",
    "    print(pred_bands)\n",
    "\n",
    "resultant_image = xr.open_rasterio(storage_path+'results.tiff').assign_coords(band=pred_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb407f-1138-4e68-9948-40c543246984",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05212b-01f9-42ed-aad6-596aecdb8369",
   "metadata": {},
   "source": [
    "Now that we have successfully created a one-band image of probabilities, all that is left is to visualise it. To do this, we write a function to plot a heatmap of probabilities. In addition to the heatmap, we will also plot the actual map of the area in question, and the binary classification regions of the probability heatmap. The latter is simply a binary mask of the probability heatmap, 1 where the probability is greater than 0.5 and 0 elsewhere. \n",
    "\n",
    "To help visualise the effectiveness of our model, we plot the frog occurrences over top of each image. This can give us an idea of where our model is doing well, and where it is doing poorly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61111823-98a5-4260-a86a-94f54f472416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_heatmap(resultant_image, species_names, frog_data, title, crs = {'init':'epsg:4326'}):\n",
    "    \"\"\"Plots a real map, probability heatmap, and model classification regions for the probability image from our model.\n",
    "\n",
    "    Arguments:\n",
    "    resultant_image -- (1, n, m) xarray of probabilities output from the model\n",
    "    frog_data -- Dataframe of frog occurrences, indicated with a 1 in the occurrenceStatus column. \n",
    "                 Must contain [\"occurrenceStatus\", \"decimalLongitude\", \"decimalLatitude\"]\n",
    "    title -- string that will be displayed as the figure title\n",
    "    crs -- coordinate reference system for plotting the real map. Defaults to EPSG:4326.\n",
    "    \"\"\"\n",
    "        \n",
    "    fig, ax = plt.subplots(len(species_names), 3, figsize=(20, 10*len(species_names)), sharey=True, sharex=True)\n",
    "    \n",
    "    extent = [resultant_image.x.min(),resultant_image.x.max(),resultant_image.y.min(),resultant_image.y.max()]\n",
    "    \n",
    "    max_val = resultant_image.values.max()\n",
    "    min_val = resultant_image.values.min()\n",
    "    \n",
    "    cmap = 'Greens'\n",
    "    \n",
    "    regions_image = resultant_image.argmax(dim='band')\n",
    "    \n",
    "    aspect = (extent[1]-extent[0])/(extent[3]-extent[2])\n",
    "    print(aspect)\n",
    "    \n",
    "    for i, species in enumerate(species_names):\n",
    "        \n",
    "        species_plot = resultant_image.sel(band=species)\n",
    "        \n",
    "        # Plot real map\n",
    "        ax[i, 0].scatter(x=[extent[0], extent[1]], y=[extent[2], extent[3]], alpha=0)\n",
    "        \n",
    "        cx.add_basemap(ax[i, 0], crs=crs)\n",
    "        ax[i, 0].set_title('Real map')        \n",
    "        \n",
    "        # Plot heatmap from model\n",
    "        heatmap = species_plot.plot.imshow(\n",
    "            x='x', y='y', ax=ax[i, 1], cmap=cmap, vmin=min_val, vmax=max_val, interpolation='none', add_colorbar=False\n",
    "        )\n",
    "        ax[i, 1].set_aspect('equal')\n",
    "        ax[i, 1].set_title(f'{species}\\nModel Probability Heatmap')\n",
    "\n",
    "        # Plot binary classification from model\n",
    "        regions = xr.where(regions_image.isnull(),np.nan, regions_image==i).plot.imshow(\n",
    "            x='x', y='y', ax=ax[i, 2], cmap=cmap, vmin=min_val, vmax=max_val, interpolation='none', add_colorbar=False\n",
    "        )\n",
    "        ax[i, 2].set_aspect('equal')\n",
    "        ax[i, 2].set_title(f'{species}\\nModel Classification Regions')\n",
    "\n",
    "        # Plot real frogs\n",
    "        for j in range(3):\n",
    "            filt = frog_data.species == species\n",
    "            ax[i, j].scatter(\n",
    "                frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude, \n",
    "                color = 'dodgerblue', marker='.', alpha=0.5, label=species if j==2 else ''\n",
    "            )\n",
    "        ax[i, 2].legend()\n",
    "\n",
    "    fig.colorbar(heatmap, ax=ax, location = 'bottom', aspect=40)\n",
    "    fig.suptitle(title, x=0.5, y=0.9, fontsize=20)\n",
    "    \n",
    "    \n",
    "plot_heatmap(resultant_image, resultant_image.band.values, frog_data, f\"Logistic Regression Model Results - {region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af86f02-679e-4449-a871-28ee325c8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "segmented_image = resultant_image.argmax(dim='band')\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "\n",
    "legend_elements = []\n",
    "for i, color in zip(range(len(full_model.classes_)), prop_cycle):\n",
    "    \n",
    "    species = full_model.classes_[i]\n",
    "    \n",
    "    (\n",
    "        xr.where(segmented_image==i, segmented_image==i, np.nan)\n",
    "    ).plot.imshow(x='x', y='y', ax=ax, cmap=ListedColormap(['black', color['color']]), add_colorbar=False)\n",
    "    legend_elements.append(Patch(facecolor=color['color'], edgecolor=color['color'], label=species.replace(' ', '\\n')))\n",
    "\n",
    "ax.legend(handles=legend_elements, loc=(1, 0))\n",
    "ax.set_aspect('equal')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08badfa5-98bd-4962-b39a-a19966babfd6",
   "metadata": {},
   "source": [
    "#### In-Sample Evaluation\n",
    "\n",
    "Now that we have visualised the model on the Richmond area, we can calculate some performance metrics to guage the effectiveness of the model. Again, it must be stressed that this is the in-sample performance - the performance on the training set. Hence, the values will tend to overestimate its performance -  so don't get too excited!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db621c-d83f-4ffc-ba7e-8579a79da9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "predictions = full_model.predict(X)\n",
    "\n",
    "print(f\"F1 Score: {f1_score(y, predictions)}\")\n",
    "print(f\"Accuracy: {accuracy_score(y, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ea862-0e9f-469f-8d18-f790cd738304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(full_model, X, y, display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Sentinel-2 and JRC Logistic\\nRegression Model Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d77515-bbdc-48aa-b21f-5dd6aff7a52c",
   "metadata": {},
   "source": [
    "#### Out-of-sample evaluation\n",
    "\n",
    "When evaluating a machine learning model, it is essential to correctly and fairly evaluate the model's ability to generalise. This is because models have a tendancy to overfit the dataset they are trained on. To estimate the out-of-sample performance, we will use k-fold cross-validation. This technique involves splitting the training dataset into folds, in this case we will use 10. Each iteration, the model is trained on all but one of the folds, which is reserved for testing. This is repeated until all folds have been left out once. At the end of the process, we will have 10 metrics which can be averaged, giving a more reliable and valid measure of model performance. \n",
    "\n",
    "`Scikit-learn` has built-in functions that can assist in k-fold cross validation. In particular, we will use `StratifiedKFold` to split our data into folds, ensuring there is always a balanced number of frogs and non-frogs in each fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e992d-08cd-4ce6-9330-852263bd0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv_model = LogisticRegression()\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=420, shuffle=True)\n",
    "metrics = {'F1': f1_score, 'Accuracy': accuracy_score}\n",
    "results = {'F1': [], 'Accuracy': []}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    # Split the dataset\n",
    "    print(f\"Fold {i+1} of {n_folds}\")\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model with the training set\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = cv_model.predict(X_test)\n",
    "    \n",
    "    for metric, fn in metrics.items():\n",
    "        results[metric].append(fn(y_test, predictions))\n",
    "        \n",
    "        \n",
    "print(f'\\nMetrics averaged over {n_folds} trials:')\n",
    "for metric, result in results.items():\n",
    "    print(f\"{metric}: {np.mean(result).round(2)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce602e0-0e4f-4f3b-a7a8-1496e83a7268",
   "metadata": {},
   "source": [
    "### Testing model on an arbitrary area \n",
    "\n",
    "Now that we have generated a model using data from one area, how do we apply that model to other areas? To do this, we need to write some functions that will allow us to automatically pull the required data for an arbitrary location. Specifically, we need to be able to pull all the predictor variables for a given location, as well as the actual frog sightings in that location for reference. These functions will reuse much of the code from prior notebooks, so we won't go into too much detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1997098-aae9-40fb-8812-ccf8d98e8444",
   "metadata": {},
   "source": [
    "#### Query the Hornsby Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ac600-b16e-4e22-b7b3-ebb0dfaba22c",
   "metadata": {},
   "source": [
    "For this, we will use Hornsby, NSW as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99aae4-8563-4b1d-85a5-d48a0c1dd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hornsby\n",
    "min_lon, min_lat = (151.02, -33.75)  # Lower-left corner\n",
    "max_lon, max_lat = (151.13, -33.63)  # Upper-right corner\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7, 7))\n",
    "ax.scatter(x=[min_lon, max_lon], y=[min_lat, max_lat])\n",
    "cx.add_basemap(ax, crs=crs)\n",
    "ax.set_title(\"Berowra Valley National Park, Hornsby NSW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96679e57-daa7-40ef-98f5-4a2134fd7f4d",
   "metadata": {},
   "source": [
    "Firstly, we grab all frog occurrences in the area from 1800 until 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11d7e6-b058-43df-8c5f-0584d8667336",
   "metadata": {},
   "outputs": [],
   "source": [
    "hornsby_frogs = get_frogs(bbox, {\"year\":\"1800,2022\"}, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecbe983-1545-439a-964e-fa7a9287d6d2",
   "metadata": {},
   "source": [
    "Next, we obtain the predictor variables from the planetary computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bc371-c78e-4f1f-886a-b9a99534b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define products and query parameters for the planetary computer\n",
    "hornsby_datasets = get_predictor_datasets(products, bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e20e29b-9bee-4255-9be8-e5f735bee471",
   "metadata": {},
   "source": [
    "Finally, we can use the `create_predictor_image` and `predict_frogs` functions from before to create the probability heatmap of the new area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f166278-57d4-47b2-9b60-ed1df953beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hornsby_predictor_image = create_predictor_image(hornsby_datasets)\n",
    "hornsby_resultant_image = predict_frogs(hornsby_predictor_image, full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef784656-9801-4192-bdc4-74019637ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "plot_heatmap(hornsby_resultant_image, hornsby_frogs, \"Logistic Regression Model Results - Hornsby, NSW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454538c8-6bab-4358-a3f9-b02479c91299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ey_ds",
   "language": "python",
   "name": "conda-env-ey_ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
