{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e516e8-c67d-4f27-8353-7f749f2eed0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2022 EY Data Science Challenge\n",
    "## Model Building - Level 1\n",
    "\n",
    "\n",
    "| Challenge | Locations                     | Spatial Res        | Species     | Satellite Data                                                |\n",
    "|-----------|-------------------------------|--------------------|-------------|---------------------------------------------------------------|\n",
    "|***1***    | Australia                     | Coarse (res=1000)  | 23 Species  | TerraClimate                                                  |\n",
    "| 2         | Australia, Costa Rica         | Moderate (res=100) | 23 Species  | TerraClimate, Sentinel-2                                      |\n",
    "| 3         | Australia, Costa Rica,<br>Europe | Fine (res=10)   | 23 Species  | TerraClimate, Sentinel-2,<br>Land cover, water extent, elevation |\n",
    "\n",
    "\n",
    "In this notebook, we will demonstrate a basic model workflow that can act as a starting point for the challenge. As specified in the first row of the table above, we will restrict this model to regions in Australia at coarse resolution (4kmx4km) with 23 specified species, and predictor variables from [TerraClimate](https://planetarycomputer.microsoft.com/dataset/terraclimate) only. In particular, we will be using four features from the TerraClimate dataset, the maximum monthly temperature, the minimum monthly temperature, the mean monthly precipitation, and the mean soil moisture, and will train a logistic regression model with these data. The TerraClimate data is sampled at a monthly temporal resolution, so metrics are calculated over the time dimension to simplify the features. We restrict this analysis to a five year window from the start of 2015 to the end of 2019, and will make the assumption that frog occurrences within that time period are representative of the entire time period (i.e. the frogs take longer than 5 years to move). \n",
    "\n",
    "Most of the functions present in this notebook were adapted from the following notebooks:\n",
    "- [TerraClimate/Weather](Weather.ipynb)\n",
    "- [GBIF/Frog](Frogs.ipynb)\n",
    "\n",
    "Again, it must be noted that this notebook is just a starting point. We make plenty of assumptions in this notebook that you may not think is best for solving the challenge effectively. You are encouraged to modify these functions, to rewrite them completely, or to try a different approach entirely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652ce4c-c75d-4484-a43a-31ffcf7a2b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Geospatial\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "from shapely.geometry import Point, Polygon\n",
    "import xarray as xr\n",
    "import rasterio.features\n",
    "import rasterio as rio\n",
    "import fsspec\n",
    "\n",
    "# API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Import Planetary Computer\n",
    "import stackstac\n",
    "import pystac\n",
    "import pystac_client\n",
    "import planetary_computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ef421-3dea-4894-a605-d1695657335b",
   "metadata": {},
   "source": [
    "### Gathering Frog Data\n",
    "\n",
    "For this demonstration, we will constrain our search to frogs in the Penrith NSW area. This gives a varied landscape of bushland, plains, rivers, and urban areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75a397-ae04-48ae-89bd-406a209be3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penrith, NSW\n",
    "region_name = 'Penrith, NSW'\n",
    "min_lon, min_lat = (150.40, -34.00)  # Lower-left corner\n",
    "max_lon, max_lat = (150.90, -33.50)  # Upper-right corner\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# Plot map of region\n",
    "crs = {'init':'epsg:4326'}\n",
    "fig, ax = plt.subplots(figsize = (7, 7))\n",
    "ax.scatter(x=[min_lon, max_lon], y=[min_lat, max_lat], alpha=0)\n",
    "cx.add_basemap(ax, crs=crs)\n",
    "ax.set_title(region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bba6da-6e94-4b01-ae6f-90dab7af487e",
   "metadata": {},
   "source": [
    "#### Fetching Frog Response Variable\n",
    "Before we can build our model, we need to query the GBIF API to obtain the frog occurrence data for our region. If you have not checked out the [frog notebook](Frogs.ipynb) yet, we recommend you do before moving on so you can better understand the following functions. The code from that notebook is wrapped up in the `get_frogs` function defined below. This function will obtain all frog occurrences for the given region in the five years from the start of 2015 to the end of 2019. It returns a geopandas dataframe of each occurrence, its species, and its latitude and longitude coordinates. The challenge restricts the species to the 23 specified in the ['australian_frogs.csv'](australian_frogs.csv) file. Note that not all 23 will be present for a given area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa92e9-714c-4868-8b37-c9d7d0813359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frogs(bbox,species_keys, species_names, query_params={}, crs={'init':'epsg:4326'}, order_key=\"952\", verbose=True):\n",
    "    \"\"\"Returns the dataframe of frog occurrences for the bounding box specified.\n",
    "    \n",
    "    Arguments:\n",
    "    bbox -- tuple of (min_lon, min_lat, max_lon, max_lat)\n",
    "    species_keys -- list of species taxonomic keys (keys from gbif database)\n",
    "    species_names -- list of names associated with species keys\n",
    "    query_params -- dictionary of query parameters to pass to the GBIF API search function\n",
    "    crs -- dictionary of the coordinate reference system, defaults to {'init':'epsg:4326'}\n",
    "    orderKey -- string of the taxonomic key for order, for frogs this is '952'\n",
    "    verbose -- boolean. If true, will print progress markers \n",
    "    \"\"\"\n",
    "    # Set query parameters\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    limit = 300\n",
    "    parameters = {\n",
    "        **query_params,\n",
    "        \"decimalLatitude\":f\"{min_lat},{max_lat}\", # Latitude range\n",
    "        \"decimalLongitude\":f\"{min_lon},{max_lon}\", # Longitude range\n",
    "        \"limit\":limit\n",
    "    }\n",
    "    \n",
    "    frogs = pd.DataFrame()\n",
    "    for species_name, species_key in zip(species_names, species_keys):\n",
    "        print(f'Fetching {species_name}, key {species_key}') if verbose else None\n",
    "        parameters[\"speciesKey\"] = species_key\n",
    "        \n",
    "        # Query API\n",
    "        offset = 0\n",
    "        while True:\n",
    "            # Fetch results\n",
    "            parameters['offset'] = offset\n",
    "            response = requests.get(\"https://api.gbif.org/v1/occurrence/search\", params = parameters).json()\n",
    "            total = response['count']\n",
    "            if total == 0:\n",
    "                break\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"{offset} of {total}\") if verbose else None\n",
    "\n",
    "            # Add results to dataframe\n",
    "            frogs = frogs.append(\n",
    "                pd.DataFrame(response['results'])\n",
    "                [[\"decimalLatitude\", \"decimalLongitude\"]]\n",
    "                .assign(\n",
    "                    occurrenceStatus = 1,\n",
    "                    species = species_name\n",
    "                )\n",
    "            )\n",
    "            if response['endOfRecords']:\n",
    "                break\n",
    "            offset += limit\n",
    "        \n",
    "    geo_frogs = gpd.GeoDataFrame(\n",
    "        frogs.reset_index(drop=True), \n",
    "        geometry=gpd.points_from_xy(frogs.decimalLongitude, frogs.decimalLatitude),\n",
    "        crs=crs\n",
    "    )\n",
    "    return geo_frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8492c05-48ab-4a2f-95c3-b424b7fdd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the date range to the GBIF API\n",
    "gbif_api_params = {\"year\":\"2015,2019\"}\n",
    "\n",
    "# Read in species data\n",
    "frog_species = pd.read_csv('australian_frogs.csv')\n",
    "\n",
    "# Get frogs!\n",
    "frog_data = get_frogs(bbox, frog_species.speciesKey, frog_species.Species, gbif_api_params, verbose=False)\n",
    "frog_data.sample(10, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cf1c2-70f8-41e3-856a-9f8592b36936",
   "metadata": {},
   "source": [
    "Below, we can visualise the frog species distribution of the area. Here, only six of the 23 are present and crinia signifera, the common eastern froglet, is the most common species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056b941-0caf-404b-8686-c0caff33a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize = (10, 12), gridspec_kw={'height_ratios':[0.7, 0.3]})\n",
    "\n",
    "# Bar chart\n",
    "bar_data = frog_data.species.value_counts()\n",
    "barchart = ax[1].bar(bar_data.index.str.replace(' ', '\\n'), bar_data)\n",
    "\n",
    "# Colour cycle to ensure colors match in both plots\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "for i, color in zip(range(len(bar_data)), prop_cycle):\n",
    "    species_name = bar_data.index[i]\n",
    "    barchart[i].set_color(color['color'])\n",
    "    barchart[i].set_label(species_name)\n",
    "    filt = frog_data.species == species_name\n",
    "    # Scatter plot\n",
    "    ax[0].scatter(frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude, marker='.', color=color['color'])\n",
    "\n",
    "# Add other features\n",
    "ax[0].set_title(f\"Frog occurrences for {region_name}\")\n",
    "ax[1].set_title(f\"Frog species distribution in {region_name}\")\n",
    "cx.add_basemap(ax[0], crs=crs, alpha=0.5) # Add basemap\n",
    "plt.xticks(rotation=45)\n",
    "fig.legend(loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26fafe-d971-4e26-860e-ffd640893626",
   "metadata": {},
   "source": [
    "The plot above shows how frog occurrences are heavily biased around urban areas, where people are more likely to come across them. They also cluster tightly around towns, parks, bush trails etc. This is one issue that would be worth addressing to maximise success in this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9baabda-08da-44ea-acf4-674cd1f4310d",
   "metadata": {},
   "source": [
    "#### Sampling for Frog Absence\n",
    "The next step in generating our training data is to sample for where frogs aren't. As mentioned above, the bias in the dataset makes this difficult to do effectively. Just because there is no frog occurrence recorded in an area, does not mean there are no frogs. However, for this demonstration, we will make the assumption that frogs are only present at occurrence locations. Our rather naive method of sampling for frog absence data is wrapped up in the `get_frog_absence` function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cbdf7-d7d4-4b42-9a99-c93dc11ccd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frog_absence(geo_frogs, bbox, crs = {'init':'epsg:4326'}, granularity=(50, 50), seed=420, border=0.05, verbose=True):\n",
    "    \"\"\"Returns a dataframe complete with frog-absence data\n",
    "    \n",
    "    Finds all grid units with no frogs, and then generates sufficient random points within those grid units to match the number of frogs.\n",
    "    \n",
    "    Arguments:\n",
    "    geo_frogs -- geopandas dataframe of frogs, outputted from get_frogs function\n",
    "    bbox -- tuple of (min_lon, min_lat, max_lon, max_lat)\n",
    "    crs -- dictionary of the coordinate reference system, defaults to {'init':'epsg:4326'}\n",
    "    granularity -- 2D tuple of the grid dimensions to divide the bounding box into - (ydim, xdim)\n",
    "    seed -- random seed for reproducable resampling\n",
    "    border -- percentage in from box\n",
    "    \"\"\"\n",
    "    # bbox definition\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    # Specify granularity of grid (50x50)\n",
    "    grid = np.array(granularity)\n",
    "    \n",
    "    # Calculate the step required to achieve granularity\n",
    "    step = np.array([max_lon - min_lon, max_lat - min_lat])/grid\n",
    "    \n",
    "    # Define unit vectors\n",
    "    up = np.array([0, 1])\n",
    "    right = np.array([1, 0])\n",
    "    \n",
    "    # Bottom corner of entire bounding box\n",
    "    bbox_bottom_corner = np.array([min_lon, min_lat])\n",
    "    \n",
    "    # bottom corner of grid unit\n",
    "    bottom_corner = bbox_bottom_corner\n",
    "    \n",
    "    non_frog_locations = []\n",
    "    for i in range(grid[0]):\n",
    "        print(f\"Scanning row {i+1} of {grid[0]}\") if verbose and i%(grid[0]//10)==0 else None\n",
    "        for j in range(grid[1]):\n",
    "            # Define grid unit\n",
    "            coords = [\n",
    "                tuple(bottom_corner), \n",
    "                tuple(bottom_corner + step*up), \n",
    "                tuple(bottom_corner + step), \n",
    "                tuple(bottom_corner + step*right)\n",
    "            ]\n",
    "            grid_unit = Polygon(coords)\n",
    "            \n",
    "            # count all frogs that intersect with this region\n",
    "            num_frogs = sum(geo_frogs.intersects(grid_unit))\n",
    "            if num_frogs == 0:\n",
    "                non_frog_locations.append(bottom_corner)\n",
    "                \n",
    "            # move bottom corner to next grid unit\n",
    "            bottom_corner = bbox_bottom_corner + step*np.array([i, j])\n",
    "    \n",
    "    # For each non-frog grid unit, generate enough random points within that unit so that the total number of non-frog samples >= frog samples\n",
    "    np.random.seed(seed)\n",
    "    non_frogs_per_unit = int(np.ceil(len(geo_frogs)/len(non_frog_locations)))\n",
    "    non_frogs = pd.DataFrame()\n",
    "    for i, unit_corner in enumerate(non_frog_locations):\n",
    "        print(f\"Generating {non_frogs_per_unit} points for location {i} of {len(non_frog_locations)}\") if verbose and i%(len(non_frog_locations)//10)==0 else None\n",
    "        for j in range(non_frogs_per_unit):\n",
    "            random_step = np.squeeze(np.random.rand(1, 2) * (step*(1-border)))\n",
    "            non_frog_point = unit_corner + random_step\n",
    "            non_frogs = non_frogs.append({'decimalLatitude':non_frog_point[1], 'decimalLongitude':non_frog_point[0]}, ignore_index=True)\n",
    "    \n",
    "    non_frogs = (\n",
    "        non_frogs\n",
    "        # Take as many non-frogs as there are frogs\n",
    "        .sample(len(geo_frogs))\n",
    "        # Assign new columns\n",
    "        .assign(\n",
    "            occurrenceStatus = 0\n",
    "        )\n",
    "        [[ \"decimalLatitude\", \"decimalLongitude\", \"occurrenceStatus\"]]\n",
    "    )\n",
    "    geo_non_frogs = gpd.GeoDataFrame(\n",
    "        non_frogs, \n",
    "        geometry=gpd.points_from_xy(non_frogs.decimalLongitude, non_frogs.decimalLatitude),\n",
    "        crs=crs\n",
    "    )\n",
    "    all_frogs = (\n",
    "        geo_frogs.append(geo_non_frogs)\n",
    "        .reset_index(drop=True)\n",
    "        .reset_index()\n",
    "        .rename(columns={'index':'key'})\n",
    "    )\n",
    "    return all_frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb857a11-1446-4680-b15c-c20dda02af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = (int((max_lon-min_lon)/0.01), int((max_lat-min_lat)/0.01))\n",
    "print(grid)\n",
    "all_frog_data = get_frog_absence(frog_data, bbox, granularity=grid, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c84370-31b1-4b8c-93f5-da0d544fda38",
   "metadata": {},
   "source": [
    "After sampling for frog absence, we finally have our training data visualised below. Again, it must be stressed that we in no way addressed the sampling bias inherent in the GBIF data. Since we will be using this training dataset for evaluation, the evaluation metrics will also be biased. You are encouraged to improve the training set collection process, particularly the frog absence sampling, until you are confident in its ability to accurately train and evaluate your model. For now, we will continue with this training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd81ab-0a5d-4d68-a504-2b34ca2d576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "filt = all_frog_data.occurrenceStatus == 1\n",
    "ax.scatter(all_frog_data[filt].decimalLongitude, all_frog_data[filt].decimalLatitude,\n",
    "           color = 'green', marker='.', alpha=0.5, label='Frogs')\n",
    "ax.scatter(all_frog_data[~filt].decimalLongitude, all_frog_data[~filt].decimalLatitude,\n",
    "           color = 'yellow', marker='.', alpha=0.5, label='Non-frogs')\n",
    "ax.legend()\n",
    "cx.add_basemap(ax, crs=crs, alpha=0.5)\n",
    "ax.set_title(f\"Training set for {region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd4236-b9a9-4622-9a59-2a3365ae9a01",
   "metadata": {},
   "source": [
    "### Getting Predictor Variables\n",
    "\n",
    "Now that we have our response variable, it is time to gather the predictor variables. Code in this section is adapted from the [Weather](Weather.ipynb) notebook.\n",
    "\n",
    "#### Fetching TerraClimate Data\n",
    "\n",
    "To get the TerraClimate data, we write a function called `get_terraclimate`. This function will fetch all data intersecting with the bounding box and will calculate various metrics over the time dimension for each coordinate. In this example, we will take six metrics from four assets, namely the mean and overall maximum monthly air temp (`tmax_mean`, `tmax_max`), mean and overall minimum monthly air temp (`tmin_mean`, `tmin_min`), mean accumulated precipitation (`ppt_mean`) and mean soil moisture (`soil_mean`), all calculated over a five year timeframe from the start of 2015 to the end of 2019.\n",
    "\n",
    "To assist in visualisations, this function has an interpolation functionality which will allow the comparitively coarse temporal resolution of the terraclimate data to be mapped to a larger set of coordinates, creating an $(n\\times m)$ image. We will choose $(512\\times 512)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f4351-847a-4c66-a764-f9a0888b9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terraclimate(bbox, metrics, time_slice=None, assets=None, features=None, interp_dims=None, verbose=True):\n",
    "    \"\"\"Returns terraclimate metrics for a given area, allowing results to be interpolated onto a larger image.\n",
    "    \n",
    "    Attributes:\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    metrics -- Nested dictionary in the form {<metric_name>:{'fn':<metric_function>,'params':<metric_kwargs_dict>}, ... }\n",
    "    time_slice -- Tuple of datetime strings to select data between, e.g. ('2015-01-01','2019-12-31')\n",
    "    assets -- list of terraclimate assets to take\n",
    "    features -- list of asset metrics to take, specified by strings in the form '<asset_name>_<metric_name>'\n",
    "    interp_dims -- Tuple of dimensions (n, m) to interpolate results to\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    collection = pystac.read_file(\"https://planetarycomputer.microsoft.com/api/stac/v1/collections/terraclimate\")\n",
    "    asset = collection.assets[\"zarr-https\"]\n",
    "    store = fsspec.get_mapper(asset.href)\n",
    "    data = xr.open_zarr(store, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    \n",
    "    # Select datapoints that overlap region\n",
    "    if time_slice is not None:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat),time=slice(time_slice[0],time_slice[1]))\n",
    "    else:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat))\n",
    "    if assets is not None:\n",
    "        data = data[assets]\n",
    "    print('Loading data') if verbose else None\n",
    "    data = data.rename(lat='y', lon='x').to_array().compute()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    combined_values = []\n",
    "    combined_bands = []\n",
    "    for name, metric in metrics.items():\n",
    "        print(f'Calculating {name}') if verbose else None\n",
    "        sum_data = xr.apply_ufunc(\n",
    "            metric['fn'], data, input_core_dims=[[\"time\"]], kwargs=metric['params'], dask = 'allowed', vectorize = True\n",
    "        ).rename(variable='band')\n",
    "        xcoords = sum_data.x\n",
    "        ycoords = sum_data.y\n",
    "        dims = sum_data.dims\n",
    "        combined_values.append(sum_data.values)\n",
    "        for band in sum_data.band.values:\n",
    "            combined_bands.append(band+'_'+name)\n",
    "        \n",
    "    # Combine metrics\n",
    "    combined_values = np.concatenate(\n",
    "        combined_values,\n",
    "        axis=0\n",
    "    )\n",
    "    combined_data = xr.DataArray(\n",
    "        data=combined_values,\n",
    "        dims=dims,\n",
    "        coords=dict(\n",
    "            band=combined_bands,\n",
    "            y=ycoords,\n",
    "            x=xcoords\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    # Take relevant bands:\n",
    "    combined_data = combined_data.sel(band=features)\n",
    "    \n",
    "    if interp_dims is not None:\n",
    "        print(f'Interpolating image') if verbose else None\n",
    "        interp_coords = (np.linspace(bbox[0], bbox[2], interp_dims[0]), np.linspace(bbox[1], bbox[3], interp_dims[1]))\n",
    "        combined_data = combined_data.interp(x=interp_coords[0], y=interp_coords[1], method='nearest', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7da9ea-10ed-418e-a803-ea4db74e0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to measure over time dimension\n",
    "metrics = {\n",
    "    'mean':{\n",
    "        'fn':np.nanmean,\n",
    "        'params':{}\n",
    "    },\n",
    "    'min':{\n",
    "        'fn':np.nanmin,\n",
    "        'params':{}\n",
    "    },\n",
    "    'max':{\n",
    "        'fn':np.nanmax,\n",
    "        'params':{}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Date range to take\n",
    "time_slice = ('2015-01-01','2019-12-31')\n",
    "\n",
    "# Measurements to take\n",
    "assets=['tmax', 'tmin', 'ppt', 'soil']\n",
    "\n",
    "# Features to take, in form '<asset>_<metric>'\n",
    "features=['tmax_max', 'tmax_mean', 'tmin_min', 'tmin_mean', 'ppt_mean', 'soil_mean']\n",
    "\n",
    "# Interpolate values to a 512x512 image\n",
    "interp_dims = (512, 512)\n",
    "\n",
    "weather_data = get_terraclimate(bbox, metrics, time_slice=time_slice, assets=assets, features=features, interp_dims=interp_dims)\n",
    "display(weather_data.band.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c46b7c-5a21-4311-bd0c-265eae7e7a03",
   "metadata": {},
   "source": [
    "#### Visualising the TerraClimate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a3347-a22d-4369-ae28-131326f72bc5",
   "metadata": {},
   "source": [
    "The spatial distribution of the six variables are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d8700-710d-4f39-8d7f-661fd29f583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 3\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(13, 7), sharex=True, sharey=True)\n",
    "\n",
    "bands = weather_data.band.values\n",
    "filt = all_frog_data.occurrenceStatus == 1\n",
    "cmaps = [\"cool\", \"cool\", \"cool\", \"cool\", \"Blues\", \"BrBG\"]\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    xr.plot.imshow(weather_data[i], 'x', 'y', cmap=cmaps[i], ax=ax[i//ncol, i%ncol]) \n",
    "    ax[i//ncol, i%ncol].set_title(bands[i])\n",
    "    ax[i//ncol, i%ncol].scatter(all_frog_data[filt].decimalLongitude, all_frog_data[filt].decimalLatitude,\n",
    "                                color = 'yellow', marker='.', alpha=0.5, label='Frogs' if i==0 else '')\n",
    "\n",
    "fig.suptitle(\"Spatial distribution of Terraclimate variables\", fontsize=20)\n",
    "fig.legend(loc=(0.85, 0.933))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd00439-c77f-4aaf-9cf7-274457de8b2d",
   "metadata": {},
   "source": [
    "The frequency distribution of each variable is displayed below. There is some skewness present in a few variables, so you might want to address this when training your own model. Depending on the type of model you decide to train, some of the variables might require normalisation, standardisation, or transformation. For now, we will proceed with the variables as they come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e9aaf-6b2c-4587-8b32-64e739591615",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 3\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(13, 7))\n",
    "\n",
    "bands = weather_data.band.values\n",
    "filt = all_frog_data.occurrenceStatus == 1\n",
    "cmaps = [\"cool\", \"cool\", \"cool\", \"cool\", \"Blues\", \"BrBG\"]\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    xr.plot.hist(weather_data[i], ax=ax[i//ncol, i%ncol]) #, cmap=cmaps[i], ) \n",
    "    # ax[i//ncol, i%ncol].set_title(bands[i])\n",
    "    # ax[i//ncol, i%ncol].scatter(all_frog_data[filt].decimalLongitude, all_frog_data[filt].decimalLatitude,\n",
    "                                # color = 'yellow', marker='.', alpha=0.5, label='Frogs' if i==0 else '')\n",
    "\n",
    "fig.suptitle(\"Frequency distribution of TerraClimate variables\",  fontsize=20)\n",
    "# fig.legend(loc=(0.85, 0.933))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0774bc5-4dff-4812-a1c6-70768abca0c9",
   "metadata": {},
   "source": [
    "### Joining Pretictors to the Response Variable\n",
    "\n",
    "Now that we have read in our predictor variables, we need to join them onto the response variable of frogs. To do this, we loop through the frog occurrence data and assign each frog occurrence the closest predictor pixel value from each of the predictor variables based on the geo-coordinates. The `sel` method of the xarray dataarray comes in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ac1e6-ff3d-41b3-a0ba-5da2acd2e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_features(model_data, predictor_image):\n",
    "    \"\"\"Joins the features from each feature dataset onto each response variable. \n",
    "\n",
    "    Arguments:\n",
    "    model_data -- dataframe containing the response variable along with [\"decimalLongitude\", \"decimalLatitude\", \"key\"]\n",
    "    all_datasets -- list of feature datasets stored as xarray dataarrays, indexed with geocoordinates\n",
    "    \"\"\"\n",
    "    # For each latitude and longitude coordinate, find the nearest predictor variable pixel values\n",
    "    data_per_point = pd.DataFrame()\n",
    "    for j, (lon, lat, key) in enumerate(zip(model_data.decimalLongitude, model_data.decimalLatitude, model_data.key)):\n",
    "        # Print out some progress markers\n",
    "        if (j+1)%(len(model_data)//10)==0:\n",
    "            print(f\"{j+1} of {len(model_data)}\")\n",
    "\n",
    "        # Get the predictor pixel at the site of the frog occurrence\n",
    "        nearest_point = predictor_image.sel(y=lat, x=lon, method=\"nearest\")\n",
    "\n",
    "        # Prepare values and columns and save them in a dataframe, saving the join key for later reference\n",
    "        values = np.concatenate((np.squeeze(nearest_point.values), np.array([key])))\n",
    "        columns = list(nearest_point.band.values) + ['key']\n",
    "        data_per_point = data_per_point.append(\n",
    "            pd.DataFrame(\n",
    "                np.array([values]), \n",
    "                columns=columns\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Join the predictor variables we just collected back onto the frog data\n",
    "    model_data = model_data.merge(\n",
    "        data_per_point,\n",
    "        on = ['key'],\n",
    "        how = 'inner'\n",
    "    )\n",
    "        \n",
    "    return model_data\n",
    "\n",
    "model_data = join_features(all_frog_data, weather_data)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb154fe-e72c-4e0f-b4ea-5a20384de3f5",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Now that we have the data in a format appropriate for machine learning, we can begin training a model. For this demonstration notebook, we will use a basic logistic regression model from the [scikit-learn](https://scikit-learn.org/stable/) library. This library offers a wide range of other models, each with the capacity for extensive parameter tuning and customisation capabilities.\n",
    "\n",
    "Scikit-learn models require separation of predictor variables and the response variable. We store the predictor variables in dataframe `X` and the response in the array `y`. We must make sure to drop the response variable from `X`, otherwise the model will have the answers! It also doesn't make sense to use latitude and longitude as predictor variables in such a confined area, so we drop those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dd94e-ba93-4667-897b-3923d3712567",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = LogisticRegression()\n",
    "# Separate the predictor variables from the response\n",
    "X = (\n",
    "    model_data\n",
    "    .drop(['key', 'decimalLongitude', 'decimalLatitude', 'occurrenceStatus', 'species', 'geometry'], 1)\n",
    ")\n",
    "y = model_data.occurrenceStatus.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb6222-b558-4314-bf1f-2b64dfd9d3dd",
   "metadata": {},
   "source": [
    "For now, we will train the model using all of our training data. Hence, this section will only reflect the in-sample performance of our model, and not the out-of-sample performance. Out-of-sample performance is crucial in estimating how a model will generalise to areas other than the training sight. We will attempt to evaluate the out-of-sample performance of this model in a later section, but for now we can have some fun visualising the in-sample performance for the training area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15029b33-daf5-4c4b-8099-de434c74600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565957c9-cba5-4948-84b6-c8f74f4cf598",
   "metadata": {},
   "source": [
    "### Model Prediction\n",
    "\n",
    "#### Predict Training Set\n",
    "\n",
    "Logistic regression is a machine learning model that estimates the probability of a binary response variable. In our case, the model will output the probability of a frog being present at a given location. To obtain the predictions for our training set, we simply use the `predict` method on our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b014512-659b-4f72-9102-b2b31c51bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = full_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51835e-6061-4db0-9ad1-3a2510c6b271",
   "metadata": {},
   "source": [
    "#### Predict Entire Region\n",
    "\n",
    "We also want to perform predictions over the entire region, not just the points in our training set. To do this, we will define another function called `predict_frogs` that will take our interpolated predictor variable image in, along with our logistic regression model, and output the probabilities for each pixel in the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a306561-6f2b-4f0d-9ede-b98b702ac226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frogs(predictor_image, model):\n",
    "    \"\"\"Returns a (1, n, m) xarray where each pixel value corresponds to the probability of a frog occurrence.\n",
    "    \n",
    "    Takes in the multi-band image outputted by the `create_predictor_image` function as well as the\n",
    "    trained model and returns the predictions for each pixel value. Firstly, the $x$ and $y$ indexes\n",
    "    in the predictor image are stacked into one multi-index $z=(x, y)$ to produce an $k\\times n$\n",
    "    array, which is the format required to feed into our logistic regression model. Then, the array\n",
    "    is fed into the model, returning the model's predictions for the frog likelihood at each pixel. \n",
    "    The predicted probabilities are then indexed by the same multi-index $z$ as before, which allows \n",
    "    the array to be unstacked and returned as a one-band image, ready for plotting.\n",
    "\n",
    "    Arguments:\n",
    "    predictor_image -- (K, n, m) xarray, where K is the number of predictor variables.\n",
    "    model -- sklearn model with K predictor variables.\n",
    "    \"\"\"\n",
    "    # Stack up pixels so they are in the appropriate format for the model\n",
    "    predictor_image = predictor_image.stack(z=(\"y\", \"x\")).transpose()\n",
    "    \n",
    "    # Calculate probability for each pixel point \n",
    "    probabilities = model.predict_proba(\n",
    "        predictor_image\n",
    "    )\n",
    "\n",
    "    # Just take probability of frog (class=1)\n",
    "    probabilities = probabilities[:,1]\n",
    "\n",
    "    # Add the coordinates to the probabilities, saving them in an xarray\n",
    "    resultant_image = xr.DataArray(\n",
    "        data=probabilities,\n",
    "        dims=['z'],\n",
    "        coords=dict(\n",
    "            z=predictor_image.z\n",
    "        )\n",
    "    )\n",
    "    # Unstack the image\n",
    "    resultant_image = resultant_image.unstack()\n",
    "    return resultant_image\n",
    "\n",
    "# Calculate probability for each pixel point \n",
    "resultant_image = predict_frogs(weather_data, full_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca09d5-b7d1-42cf-80cb-66fc23225974",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Now that we have trained our model and made some predictions, all that is left is to evaluate it. We will do this by first visualising the output of the model with a probability heatmap. Then, we will evaluate both its in-sample and out-of-sample performance using the training set we have generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08badfa5-98bd-4962-b39a-a19966babfd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### In-Sample Evaluation\n",
    "\n",
    "Now that we have our model predictions for the training set stored in the `predictions` variable, we can calculate some performance metrics to guage the effectiveness of the model. Again, it must be stressed that this is the in-sample performance - the performance on the training set. Hence, the values will tend to overestimate its performance. Additionally, the training set itself is biased and this notebook made no effort to address this. The model evaluation metrics are only as good as the test data, so the metrics themselves will also be biased. Thus, these metrics are NOT truly indicative of this model's performance.\n",
    "\n",
    "In this example, we will use `f1_score` and `accuracy_score` from Scikit-learn. Scikit-learn provides many other metrics that can be used for evaluation. You can even code your own if you think it will assist you in evaluating your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db621c-d83f-4ffc-ba7e-8579a79da9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score: {np.mean(f1_score(y, predictions)).round(2)}\")\n",
    "print(f\"Accuracy: {np.mean(accuracy_score(y, predictions)).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ea862-0e9f-469f-8d18-f790cd738304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(full_model, X, y, display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Model Level 1: Logistic\\nRegression Model In-Sample Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47abbe6d-665d-4469-9c33-3eeb623159d4",
   "metadata": {},
   "source": [
    "From above, we see that the model is able to achieve a moderately high F1 score and accuracy. However, from the confusion matrix we can see that it gets about half of the absent locations incorrect (false positives). Perhaps we can gain more insight into what is causing the model to do this by visualising the model over the area in question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c1c74-e309-4fb5-9063-e680651f3bc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Probability Heatmap\n",
    "\n",
    "To create the probability heatmap, we write a function called `plot_heatmap`. This function will take in the model predictions from the entire region as stored in the `resultant_image` variable, and visualise these probabilities as a heatmap. In addition to the heatmap, we will also plot the actual map of the area in question, and the binary classification regions of the probability heatmap. The latter is simply a binary mask of the probability heatmap, 1 where the probability is greater than 0.5 and 0 elsewhere. \n",
    "\n",
    "To help visualise the effectiveness of our model, we plot the frog occurrences over top of each image. This can give us an idea of where our model is doing well, and where it is doing poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb12b7-395d-4741-8ed6-0487f6d611d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(resultant_image, frog_data, title, crs = {'init':'epsg:4326'}):\n",
    "    \"\"\"Plots a real map, probability heatmap, and model classification regions for the probability image from our model.\n",
    "\n",
    "    Arguments:\n",
    "    resultant_image -- (1, n, m) xarray of probabilities output from the model\n",
    "    frog_data -- Dataframe of frog occurrences, indicated with a 1 in the occurrenceStatus column. \n",
    "                 Must contain [\"occurrenceStatus\", \"decimalLongitude\", \"decimalLatitude\"]\n",
    "    title -- string that will be displayed as the figure title\n",
    "    crs -- coordinate reference system for plotting the real map. Defaults to EPSG:4326.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (20, 10), sharex=True, sharey=True)\n",
    "    \n",
    "    bbox = [resultant_image.x.min(),resultant_image.x.max(),resultant_image.y.min(),resultant_image.y.max()]\n",
    "\n",
    "    # Plot real map\n",
    "    ax[0].scatter(x=[bbox[0], bbox[1]], y=[bbox[2], bbox[3]], alpha=0)\n",
    "    cx.add_basemap(ax[0], crs=crs)\n",
    "    ax[0].set_title('Real map')\n",
    "    \n",
    "    # Plot heatmap from model\n",
    "    heatmap = ax[1].imshow(\n",
    "        resultant_image, cmap='PiYG', vmin=0, vmax=1.0, interpolation='none', extent=bbox, origin='lower'\n",
    "    )\n",
    "    ax[1].set_title('Model Probability Heatmap')\n",
    "\n",
    "    # Plot binary classification from model\n",
    "    regions = ax[2].imshow(\n",
    "        resultant_image > 0.5, cmap='PiYG', vmin=0, vmax=1.0, interpolation='none', extent=bbox, origin='lower'\n",
    "    )\n",
    "    ax[2].set_title('Model Classification Regions')\n",
    "\n",
    "    # Plot real frogs\n",
    "    for i, axis in enumerate(ax):\n",
    "        filt = frog_data.occurrenceStatus == 1\n",
    "        axis.scatter(\n",
    "            frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude, \n",
    "            color = 'dodgerblue', marker='.', alpha=0.5, label='Frogs' if i==0 else ''\n",
    "        )\n",
    "\n",
    "    fig.colorbar(heatmap, ax=ax, location = 'bottom', aspect=40)\n",
    "    fig.legend(loc = (0.9, 0.9))\n",
    "    fig.suptitle(title, x=0.5, y=0.9, fontsize=20)\n",
    "    \n",
    "plot_heatmap(resultant_image, all_frog_data, \"Logistic Regression Model Results - Penrith, NSW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab57d7-29c2-4cf9-b6cf-644ff6504a7d",
   "metadata": {},
   "source": [
    "From the plots above, we can see that the model is basically dividing the region into two regions of basically equal area. Because the frog absence points are roughly uniformly distributed across the region, the equally sized classification regions accounts for the high rate of false positives seen in the confusion matrix. Additionally, due to the coarse spatial resolution of the TerraClimate data, the classification regions are very blocky. You don't need to be a frog expert to see that this model is quite limited in its ability to identify frog habitats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d77515-bbdc-48aa-b21f-5dd6aff7a52c",
   "metadata": {},
   "source": [
    "#### Out-of-Sample Evaluation\n",
    "\n",
    "When evaluating a machine learning model, it is essential to correctly and fairly evaluate the model's ability to generalise. This is because models have a tendancy to overfit the dataset they are trained on. To estimate the out-of-sample performance, we will use k-fold cross-validation. This technique involves splitting the training dataset into folds, in this case we will use 10. Each iteration, the model is trained on all but one of the folds, which is reserved for testing. This is repeated until all folds have been left out once. At the end of the process, we will have 10 metrics which can be averaged, giving a more reliable and valid measure of model performance. \n",
    "\n",
    "Scikit-learn has built-in functions that can assist in k-fold cross validation. In particular, we will use `StratifiedKFold` to split our data into folds, ensuring there is always a balanced number of frogs and non-frogs in each fold.\n",
    "\n",
    "Again, these metrics are derived from a biased sample, so be careful what you infer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e992d-08cd-4ce6-9330-852263bd0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = LogisticRegression()\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=420, shuffle=True)\n",
    "metrics = {'F1': f1_score, 'Accuracy': accuracy_score}\n",
    "results = {'predicted':[], 'actual':[]}\n",
    "scores = {'F1': [], 'Accuracy': []}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    # Split the dataset\n",
    "    print(f\"Fold {i+1} of {n_folds}\")\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model with the training set\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = cv_model.predict(X_test)\n",
    "    \n",
    "    for metric, fn in metrics.items():\n",
    "        scores[metric].append(fn(y_test, predictions))\n",
    "        \n",
    "    results['predicted'].extend(predictions)\n",
    "    results['actual'].extend(list(y_test))\n",
    "        \n",
    "print(f'\\nMetrics averaged over {n_folds} trials:')\n",
    "for metric, result in scores.items():\n",
    "    print(f\"{metric}: {np.mean(result).round(2)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239a36d-4d40-4ce8-ace4-ccad12bc0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_predictions(results['actual'], results['predicted'], display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Model Level 1: Logistic Regression Model\\n10-fold Cross Validation Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddcdfe-309f-43e5-862a-24497d12450e",
   "metadata": {},
   "source": [
    "The results from the 10-fold cross validation are similar but slightly lower than the in-sample metrics, as expected. We see similar behavour in the rate of false positives that we saw in the in-sample performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41938b59-c2be-454e-be3a-80251330aa62",
   "metadata": {},
   "source": [
    "### Get Frogging!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec962f-89f9-465e-9269-73374840dcb8",
   "metadata": {},
   "source": [
    "Now that you have witnessed a basic approach to model training, its time to try your own approach! Feel free to modify any of the functions presented in this notebook. Be sure to address some of the assumptions made here, particularly around frog absence sampling to address the sampling bias in the dataset. You might even decide on a completely different training set, such as classifying regions rather than points. Do whatever you think will create the best model for predicting frog habitats. Best of luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327b897-de8c-4436-a0d6-3ff0e957b518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ey_ds",
   "language": "python",
   "name": "conda-env-ey_ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
