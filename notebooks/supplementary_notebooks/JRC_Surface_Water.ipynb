{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2022 EY Challenge\n",
    "\n",
    "## JRC Global Surface Water Data\n",
    "\n",
    "This notebook can be used to extract surface water data for any location. The dataset was generated from data collected by three separate satellites: Landsat 5, 7, and 8. The data provides statistics on the extent and change of surface water for different locations and times. You can learn more about the dataset [here](https://planetarycomputer.microsoft.com/dataset/jrc-gsw), or see a slightly more detailed description [here](https://developers.google.com/earth-engine/datasets/catalog/JRC_GSW1_3_GlobalSurfaceWater).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import common GIS tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio.features\n",
    "import rasterio as rio\n",
    "# import xrspatial.multispectral as ms\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import stackstac\n",
    "import pystac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Table visualisation tools\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discover and load the data for analysis\n",
    "\n",
    "First, we define our area of interest using latitude and longitude coordinates. Our test region is near Richmond, NSW, Australia. The first line defines the lower-left corner of the bounding box and the second line defines the upper-right corner of the bounding box. GeoJSON format uses a specific order: (longitude, latitude), so be careful when entering the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Richmond\n",
    "min_lon, min_lat = (150.62, -33.69)  # Lower-left corner\n",
    "max_lon, max_lat = (150.83, -33.48)  # Upper-right corner\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# # Bangladesh\n",
    "# min_lon, min_lat = (90.81, 24.08)  # Lower-left corner\n",
    "# max_lon, max_lat = (91.20, 24.80)  # Upper-right corner\n",
    "# bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# # Hornsby\n",
    "# min_lon, min_lat = (151.04, -33.72)  # Lower-left corner\n",
    "# max_lon, max_lat = (151.11, -33.67)  # Upper-right corner\n",
    "# bbox = (min_lon, min_lat, max_lon, max_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `pystac_client` we can search the Planetary Computer's STAC endpoint for items matching our query parameters.\n",
    "<br>The surface water data is an amalgamation of many thousands of timeseries images, so there is no need to query a timeframe or filter for cloud cover. (The change in time is captured in the `change` band, which quantifies the change in surface water between epoch 1984-1999 and epoch 2000-2019.)\n",
    "<br>The result is one, clean scene for our region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "search = stac.search(\n",
    "    bbox=bbox,\n",
    "    collections=[\"jrc-gsw\"]\n",
    ")\n",
    "\n",
    "items = list(search.get_items())\n",
    "print('This is the number of scenes that touch our region:',len(items))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since theres only one scene\n",
    "item = items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below extracts the bands that are available, as well as their descriptions. We save the asset keys in `cog_assets` so that we can reference them later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract asset info and store it in a table (purely for display purposes)\n",
    "assets = pd.DataFrame()\n",
    "for asset_key, asset in item.assets.items():\n",
    "    if asset.media_type == pystac.MediaType.COG:\n",
    "        asset_info = pd.DataFrame(asset.to_dict())\n",
    "        asset_info['STAC Key'] = asset_key\n",
    "        assets = assets.append(asset_info)\n",
    "        \n",
    "assets = assets.reset_index(drop=True)\n",
    "assets = assets[['STAC Key', 'title', 'description']]\n",
    "          \n",
    "# Save asset keys to list\n",
    "cog_assets = list(assets['STAC Key'])\n",
    "\n",
    "# Truncate description for display\n",
    "assets.description = assets.description.str.wrap(100)\n",
    "display(HTML(assets.to_html().replace(\"\\\\n\",\"<br>\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each asset has an associated colourmap that is worth extracting to make our plots more aesthetically pleasing. The following extracts the colourmaps and stores them in matplotlib cmap format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = {}\n",
    "for asset_key in cog_assets:\n",
    "    asset_url = item.assets[asset_key].href\n",
    "    with rasterio.open(asset_url) as src:\n",
    "        colormap_def = src.colormap(1)  # get metadata colormap for band 1\n",
    "        colormap = [\n",
    "            np.array(colormap_def[i]) / 256 for i in range(256)\n",
    "        ]  # transform to matplotlib color format\n",
    "    cmaps[asset_key] = ListedColormap(colormap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the data into an [xarray](https://xarray.pydata.org/en/stable/) DataArray using [stackstac](https://stackstac.readthedocs.io/) and then \"clip\" the data to only the pixels within our region (bounding box). We will keep all six bands. There are also several other <b>important settings for the data</b>: We have changed the projection to epsg=4326 which is standard latitude-longitude in degrees. We have specified the spatial resolution of each pixel to be 10-meters. This resolution can be easily changed below (e.g. 100 meters) to reduce the data volume of the final GeoTIFF output. This change may be neccesary when considering larger analysis regions. Also, we have selected a resampling method of \"average\" that will find the mean value of each band to create new pixels. This is only needed when the resolution is changed from 10-meters to larger values (e.g. 100 meters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pixel resolution for the final product\n",
    "# Define the scale according to our selected crs, so we will use degrees\n",
    "resolution = 10  # meters per pixel \n",
    "scale = resolution / 111320.0 # degrees per pixel for crs=4326 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    stackstac.stack(\n",
    "        item,\n",
    "        epsg=4326, # Use common Lat-Lon coordinates\n",
    "        resolution=scale, # Use degrees for crs=4326\n",
    "        bounds_latlon = bbox,\n",
    "        # resampling=rasterio.enums.Resampling.average, # Average resampling method (only required when resolution >10)\n",
    "        # assets=[\"extent\"], \n",
    "        chunksize=4096,  \n",
    "    )\n",
    "    # .where(lambda x: x > 0, other=np.nan)  # sentinel-2 uses 0 as nodata\n",
    "    # .assign_coords(band=lambda x: x.title)  # use common names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data matching our query isn't too large we can persist it in distributed memory. Once in memory, subsequent operations will be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the time dimension, since there is only one item\n",
    "data = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "import cv2\n",
    "\n",
    "dpi = 200\n",
    "fig = plt.figure(frameon=False, dpi=dpi)\n",
    "\n",
    "for i, asset_key in enumerate(cog_assets):\n",
    "    ax1 = fig.add_subplot(int(f\"23{i+1}\"))\n",
    "    ax1.set_title(asset_key, fontdict={\"fontsize\": 5})\n",
    "    ax1.set_axis_off()\n",
    "    img = np.array(data.sel(band = asset_key))\n",
    "    plt.imshow(\n",
    "        # cv2.dilate(img, np.ones((50,50)), iterations=1),\n",
    "        img,\n",
    "        norm=Normalize(0, 255),  \n",
    "        cmap=cmaps[asset_key]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output data to a NetCDF4 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep x, y, and band coordinates (others cause trouble when saving)\n",
    "for key in list(data.coords.keys()):\n",
    "    if key not in ['x', 'y', 'band']:\n",
    "        del data.coords[key]\n",
    "\n",
    "# Remove all attributes (also cause trouble)\n",
    "data.attrs = {}\n",
    "\n",
    "# Save to file\n",
    "filename = \"jrc_mosaic_sample.nc\"\n",
    "data.to_netcdf(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "xr.open_dataset(filename).load().to_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to a GeoTIFF file (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"jrc_mosaic_sample.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will report the pixel dimensions of our mosaic file. Recall that pixel resolution will impact the dimensions.\n",
    "data.sel(band=\"occurrence\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = data.sel(band=\"occurrence\").shape[0]\n",
    "width = data.sel(band=\"occurrence\").shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(filename,'w',driver='GTiff',width=width,height=height,count=len(cog_assets),compress='lzw',dtype='float64', crs=\"EPSG:4326\") as dst:\n",
    "    dst.write(data)\n",
    "    \n",
    "    for i, band in enumerate(cog_assets):\n",
    "        img = data.sel(band=band)\n",
    "        dst.write_band(i+1, img)\n",
    "        dst.set_band_description(i+1, band)\n",
    "        \n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the location and size of the new output file\n",
    "!ls *.tiff -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data### How will the participants use this data?\n",
    "The GeoTIFF file will contain the Lat-Lon coordinates of each pixel and will also contain the mean band values (Red, Green, Blue, NIR) for each pixel as separate data layers. These band values can be easily used to calculate indices such as NDVI (vegetation) or NDWI (water). Since the FrogID data is also Lat-Lon position, it is possible to find the closest Sentinel-2 mosaic pixel using code similar to what is demonstrated below. Once this pixel is found, then the corresponding spectral data (values) can be used for modeling species distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ey_ds",
   "language": "python",
   "name": "conda-env-ey_ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
