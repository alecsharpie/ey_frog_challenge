{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67b5b78-896b-4c8d-b1d1-39792c21c464",
   "metadata": {},
   "source": [
    "# Frog Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941e53c-818b-4b3a-8cf1-2a3fb86cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl https://upload.wikimedia.org/wikipedia/commons/e/ea/Litoria_fallax_range.PNG > pictures/Litoria_fallax_range.PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a34371-3f4f-4fe3-9560-f52216cacad4",
   "metadata": {},
   "source": [
    "Litoria fallax\n",
    "https://en.wikipedia.org/wiki/Eastern_dwarf_tree_frog\n",
    "\n",
    "\n",
    "About 200-301 eggs are laid at each amplexus, and clumps of spawn contain up to 35 eggs. The minimum tadpole lifespan is 118 days, at a consist temperature of 20 °C. Metamorphosis occurs from January to March, the metamorphs resemble the adults and are very small, only 9–13 mm in length.\n",
    "\n",
    "\n",
    "\n",
    "### Range Map\n",
    "<center>\n",
    "<img src=\"pictures/Litoria_fallax_range.PNG\" width=\"250\" height=\"170\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e516e8-c67d-4f27-8353-7f749f2eed0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Level 1: Local Frog Discovery Tool benchmark notebook\n",
    "\n",
    "## Challenge Level 1 Overview\n",
    "\n",
    "\n",
    "Welcome to the 2022 EY Data Science Challenge! This is the first challenge aimed at beginner/intermediate participants that have little to no experience in data science and programming. For more experienced participants, we recommend undertaking challenge level 2 outlined [here](Model_Level_2.ipynb). If you choose to undertake the first level of the challenge, you will be developing a species distribution model (SDM) for one Australian frog species using only variables from the TerraClimate dataset. A species distribution model is a specific type of machine learning model that aims to predict the distribution of a biological species across geographic space and time. Such models have become increasingly important in conservation efforts globally to better understand and map the habitats of species of interest, particularly threatened or endangered species. \n",
    "\n",
    "The frog species identified for this challenge is Litoria fallax, the eastern dwarf tree frog pictured below. In addition to assisting our understanding of this specific frog species, a successful frog SDM will have broader implications in quantifying biodiversity. This is because frogs are incredibly sensitive to environmental changes, so any changes in their species distribution may indicate an underlying change to biodiversity in the area. \n",
    "\n",
    "<center>\n",
    "<img src=\"pictures/Litoria_fallax.jpg\" width=\"500\" height=\"340\">\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Challenge aim:** to develop a species distribution model for litoria fallax across Australia using weather data from the TerraClimate dataset.\n",
    "\n",
    "| Challenge | Locations                     | Spatial Res        | Species          | Satellite Data                                                |\n",
    "|-----------|-------------------------------|--------------------|------------------|---------------------------------------------------------------|\n",
    "|***1***    | Australia                     | Coarse (4km)  | 1 species  | TerraClimate                                                  |\n",
    "|2     | Australia, Costa Rica,<br>South Africa | Fine (10m)   | 15 species     | TerraClimate, Sentinel-2,<br>Land cover, water extent, elevation |\n",
    "\n",
    "In this notebook, we will demonstrate a basic model workflow that can act as a starting point for the challenge. As specified in the first row of the table above, we will restrict this model to regions in Australia at coarse resolution (4kmx4km), predicting one species against the rest of the 5 specified Australian species using only [TerraClimate](https://planetarycomputer.microsoft.com/dataset/terraclimate) predictor variables. In this demonstation, we will be using four features from the TerraClimate dataset, the maximum monthly temperature, the minimum monthly temperature, the mean monthly precipitation, and the mean soil moisture, and will train a logistic regression model with these data. The TerraClimate data is sampled at a monthly temporal resolution, so metrics are calculated over the time dimension to simplify the features. We restrict this analysis to a five year window from the start of 2015 to the end of 2019, and will make the assumption that frog occurrences within that time period are representative of the entire time period (i.e. the frogs take longer than 5 years to move). \n",
    "\n",
    "\n",
    "Most of the functions present in this notebook were adapted from the following notebooks:\n",
    "- [Training Dataset Summary](../supplementary_notebooks/dataset_summary.ipynb)\n",
    "- [TerraClimate/Weather](../supplementary_notebooks/TerraClimate.ipynb)\n",
    "\n",
    "Again, it must be noted that this notebook is just a starting point. We make plenty of assumptions in this notebook that you may not think are best for solving the challenge effectively. You are encouraged to modify these functions, to rewrite them completely, or to try a different approach entirely.\n",
    "\n",
    "\n",
    "## Load in dependencies\n",
    "\n",
    "To run this demonstration notebook, you will need to have the following packages imported below installed. This may take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5652ce4c-c75d-4484-a43a-31ffcf7a2b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Geospatial\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "import zarr # Not referenced, but required for xarray\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import fsspec\n",
    "import pystac\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import zipfile\n",
    "from itertools import cycle\n",
    "\n",
    "# Path to data folder with provided material\n",
    "data_path = '../raw_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ef421-3dea-4894-a605-d1695657335b",
   "metadata": {},
   "source": [
    "## Response Variable\n",
    "\n",
    "Before we can build our model, we need to load in the frog occurrences data and generate our response variable. To do this, we first need to unzip the training data and store it on our machine. Then we can write a function that abstracts the loading process, with the option of providing a bounding box to only take those occurrences within a region of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf305264-0afd-40c3-a9b1-3b782593ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path+'training_data/'):\n",
    "    os.mkdir(data_path+'training_data/')\n",
    "    with zipfile.ZipFile(data_path+'GBIF_training_data.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path+'training_data/')\n",
    "        \n",
    "def filter_bbox(frogs, bbox):\n",
    "    frogs = frogs[lambda x: \n",
    "        (x.decimalLongitude >= bbox[0]) &\n",
    "        (x.decimalLatitude >= bbox[1]) &\n",
    "        (x.decimalLongitude <= bbox[2]) &\n",
    "        (x.decimalLatitude <= bbox[3])\n",
    "    ]\n",
    "    return frogs\n",
    "\n",
    "def get_frogs(file, year_range=None, bbox=None):\n",
    "    \"\"\"Returns the dataframe of all frog occurrences for the bounding box specified.\"\"\"\n",
    "    columns = [\n",
    "        'gbifID','eventDate','country','continent','stateProvince',\n",
    "        'decimalLatitude','decimalLongitude','species'\n",
    "    ]\n",
    "    country_names = {\n",
    "        'AU':'Australia', 'CR':'Costa Rica', 'ZA':'South Africa','MX':'Mexico','HN':'Honduras',\n",
    "        'MZ':'Mozambique','BW':'Botswana','MW':'Malawi','CO':'Colombia','PA':'Panama','NI':'Nicaragua',\n",
    "        'BZ':'Belize','ZW':'Zimbabwe','SZ':'Eswatini','ZM':'Zambia','GT':'Guatemala','LS':'Lesotho',\n",
    "        'SV':'El Salvador', 'AO':'Angola', np.nan:'unknown or invalid'\n",
    "    }\n",
    "    continent_names = {\n",
    "        'AU':'Australia', 'CR':'Central America', 'ZA':'Africa','MX':'Central America','HN':'Central America',\n",
    "        'MZ':'Africa','BW':'Africa','MW':'Africa','CO':'Central America','PA':'Central America',\n",
    "        'NI':'Central America','BZ':'Central America','ZW':'Africa','SZ':'Africa','ZM':'Africa',\n",
    "        'GT':'Central America','LS':'Africa','SV':'Central America','AO':'Africa', np.nan:'unknown or invalid' \n",
    "    }\n",
    "    frogs = (\n",
    "        pd.read_csv(data_path+'training_data/occurrence.txt', sep='\\t', parse_dates=['eventDate'])\n",
    "        .assign(\n",
    "            country =  lambda x: x.countryCode.map(country_names),\n",
    "            continent =  lambda x: x.countryCode.map(continent_names),\n",
    "            species = lambda x: x.species.str.title()\n",
    "        )\n",
    "        [columns]\n",
    "    )\n",
    "    if year_range is not None:\n",
    "        frogs = frogs[lambda x: \n",
    "            (x.eventDate.dt.year >= year_range[0]) & \n",
    "            (x.eventDate.dt.year <= year_range[1])\n",
    "        ]\n",
    "    if bbox is not None:\n",
    "        frogs = filter_bbox(frogs, bbox)\n",
    "    return frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47010498-24fb-42b1-8ccc-3f7f89235c59",
   "metadata": {},
   "source": [
    "### Sub-sampling\n",
    "\n",
    "For this demonstration, we will constrain our search to frogs in the Greater Sydney area found between the start of 2015 to the end of 2019. This gives a varied landscape of bushland, plains, rivers, and urban areas. This is done by providing `year_range` and `bbox` parameters to the get_frogs function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75a397-ae04-48ae-89bd-406a209be3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounding box for Greater Sydney, NSW\n",
    "region_name = 'Greater Sydney, NSW'\n",
    "min_lon, min_lat = (150.15, -34.25)  # Lower-left corner\n",
    "max_lon, max_lat = (151.15, -33.25)  # Upper-right corner\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# Load in data\n",
    "all_frog_data = get_frogs(data_path+'/training_data/occurrence.txt', year_range=(2015, 2019), bbox=bbox)\n",
    "all_frog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33012401-2c91-4181-97c5-4b7f1cee5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in australia data\n",
    "all_frog_data = get_frogs(data_path+'/training_data/occurrence.txt', year_range=None, bbox=None)\n",
    "#litoria_df = all_frog_data['species'] =='Litoria Fallax'\n",
    "aus_df = all_frog_data[all_frog_data['country'] == 'Australia']\n",
    "aus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c6b93-39bd-4032-b601-56bb8b7cbf92",
   "metadata": {},
   "source": [
    "#### Spatial sampling\n",
    "\n",
    "While we have restricted our analysis to Greater Sydney for this demonstration,  you are encouraged to explore different areas to assist in creating a SDM that is representative of the habitat of litoria fallax. You could even use the entire training set, but keep in mind that loading in large areas may be quite computationally expensive. We recommend loading data in chunks that are a similar size to the bounding box we defined above.\n",
    "\n",
    "#### Temporal sampling\n",
    "\n",
    "Another area that may assist you in developing your SDM is the time dimension of the data. Each occurrence has an \"eventDate\" attribute, and the terraclimate data is taken monthly. You may want to consider whether more closely matching occurrences to timely data will improve your model. Another idea is to pool the data into larger time chunks like we have done in this notebook. This could involve extending our approach of binning the data in 5 year intervals to include occurrence data for 2010-2015, 2005-2009, etc. Either approach would allow you to utilise more of the training data which could greatly assist your SDM training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41413967-761e-46ab-9b2c-310532e8537a",
   "metadata": {},
   "source": [
    "### Addressing bias\n",
    "\n",
    "Below we define some functions to assist in plotting the frog data. This will assist us in identifying two main areas of bias. We then use these functions to plot the frog species distributions of each country. A more detailed exploration of the training dataset for this challenge can be found in the [dataset summary notebook](supplementary_notebooks/dataset_summary.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e91c6-75fb-4519-897a-f3a2599a4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_species(fig, ax, frog_data, region_name, cmap_params={'alpha':0.5}, scatter_params={'alpha':0.5}):\n",
    "    # Bar chart\n",
    "    bar_data = frog_data.species.value_counts()\n",
    "    barchart = ax[1].bar(bar_data.index.str.replace(' ', '\\n'), bar_data)\n",
    "\n",
    "    # Colour cycle to ensure colors match in both plots\n",
    "    prop_cycle = cycle(plt.rcParams['axes.prop_cycle'])\n",
    "    for i, color in zip(range(len(bar_data)), prop_cycle):\n",
    "        species_name = bar_data.index[i]\n",
    "        if len(species_name) > 19:\n",
    "            display_name = species_name.replace(' ', '\\n')\n",
    "        else:\n",
    "            display_name = species_name\n",
    "        barchart[i].set_color(color['color'])\n",
    "        barchart[i].set_label(f\"{display_name}\\nCount: {bar_data[i]}\")\n",
    "        filt = frog_data.species == species_name\n",
    "        # Scatter plot\n",
    "        ax[0].scatter(\n",
    "            frog_data[filt].decimalLongitude, \n",
    "            frog_data[filt].decimalLatitude, \n",
    "            marker='.', \n",
    "            color=color['color'],\n",
    "            **scatter_params\n",
    "        )\n",
    "\n",
    "    # Add other features\n",
    "    ax[0].set_title(f\"Frog occurrences for {region_name}\")\n",
    "    # ax[0].set_xticklabels([])\n",
    "    # ax[0].set_yticklabels([])\n",
    "    ax[1].set_title(f\"Frog species distribution in {region_name}\")\n",
    "    cx.add_basemap(ax[0], crs={'init':'epsg:4326'}, **cmap_params) # Add basemap\n",
    "    ax[1].set_xticklabels(bar_data.index.str.replace(' ', '\\n'), rotation=45)\n",
    "    ax[1].legend()\n",
    "    \n",
    "    \n",
    "def plot_barchart(bar_data, ax, bar_params={}, fold_text=True):\n",
    "    barchart = ax.bar(bar_data.index, bar_data, **bar_params)\n",
    "    prop_cycle = cycle(plt.rcParams['axes.prop_cycle'])\n",
    "    for i, color in zip(range(len(bar_data)), prop_cycle):\n",
    "        var_name = bar_data.index[i]\n",
    "        barchart[i].set_color(color['color'])\n",
    "        barchart[i].set_label(f\"{var_name}\\nCount: {bar_data[i]}\")\n",
    "    ax.set_xticklabels(bar_data.index.str.replace(' ', '\\n'), rotation=45)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74cf1c2-70f8-41e3-856a-9f8592b36936",
   "metadata": {},
   "source": [
    "Below, we can visualise the frog species distribution of the area. Here, only two of the five Australian species are present: crinia signifera, the common eastern froglet, and litoria fallax, the eastern dwarf tree frog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056b941-0caf-404b-8686-c0caff33a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(8, 15))\n",
    "plot_species(fig, ax, all_frog_data, region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6de119-ec0c-4428-abf2-05bd8d9948ed",
   "metadata": {},
   "source": [
    "#### Sampling bias\n",
    "\n",
    "The plot above shows how frog occurrences are heavily biased around urban areas, where people are more likely to come across them. They also cluster tightly around towns, parks, bush trails etc. This is one issue that would be worth addressing to maximise success in this challenge.\n",
    "\n",
    "One method of addressing the sampling bias inherent in the database is to use the occurrence points of other species as absence points for the target species. This is called pseudo-absence and is a common technique in species distribution modelling. This way, if a different species of frog has been sighted in a specific location, we can be more certain that the species we are trying to predict is not at that same location. Alternatively, if we just picked a random point where there are no frog occurrences, we cannot be certain that frogs are not in that location. It might just be that there are no walking tracks near that location, and therefore the frogs would not show up in our database.\n",
    "\n",
    "For this notebook, we will use the other species, crinia signifera - the common eastern froglet, as examples of litoria fallax's absence. We will alter our response variable to be `occurenceStatus` which will take the value of 1 if the occurrence species is litoria fallax, and 0 if the species is not litoria fallax (i.e. is crinia signifera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2c61a-7739-4218-99bf-9db393937442",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_species = 'Litoria Fallax'\n",
    "\n",
    "all_frog_data = (\n",
    "    all_frog_data\n",
    "    # Assign the occurrenceStatus to 1 for the target species and 0 for all other species.\n",
    "    # as well as a key for joining (later)\n",
    "    .assign(\n",
    "        occurrenceStatus = lambda x: np.where(x.species == target_species, 1, 0)\n",
    "    )\n",
    ")\n",
    "all_frog_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09764dff-bb95-4431-ac0d-d1f296e849eb",
   "metadata": {},
   "source": [
    "#### Class Balancing\n",
    "\n",
    "Another bias shown in the above visualisations is the class imbalance. To handle this, we will down-sample the absence points so that their numbers match that of the target species. Note that this is quite a naive approach as an isolated frog occurrence may be lost while clusters of occurrences are more likely to persist. This may not be ideal, as these isolated occurrences are often the most important data points available for frog conservationists. Developing a smarter sampling method may be a worthwhile pursuit when considering ways to improve your model.\n",
    "\n",
    "The barcharts below show the response variable before and after the classes have been balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52f2a6-c24f-4815-9fc8-463c579bd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_species_frog_data = all_frog_data[all_frog_data.occurrenceStatus == 1]\n",
    "frog_data = (\n",
    "    all_frog_data\n",
    "    [lambda x: x.occurrenceStatus == 0]\n",
    "    .sample(\n",
    "        len(target_species_frog_data), random_state=420\n",
    "    )\n",
    "    .append(target_species_frog_data)\n",
    "    # assign key for joining purposes\n",
    "    .reset_index(drop=True)\n",
    "    .assign(key=lambda x: x.index)\n",
    ")\n",
    "# Bar charts\n",
    "fig, ax = plt.subplots(1, 2, figsize = (15, 5), sharey=True, sharex=True)\n",
    "bar_data = all_frog_data.occurrenceStatus.map({1:'Present', 0:'Absent'}).value_counts()\n",
    "plot_barchart(bar_data, ax[0], bar_params={})\n",
    "ax[0].set_title('Unbalanced training set')\n",
    "balanced_bar_data = frog_data.occurrenceStatus.map({1:'Present', 0:'Absent'}).value_counts()\n",
    "plot_barchart(balanced_bar_data, ax[1], bar_params={})\n",
    "ax[1].set_title('Balanced training set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c84370-31b1-4b8c-93f5-da0d544fda38",
   "metadata": {},
   "source": [
    "After assigning absence points and balancing the classes, we finally have our training data visualised below. Again, it must be stressed that this is just one way of addressing the sampling bias and class imbalances inherent in the GBIF data and it does not address these biases completely. Since we will be using this training dataset for evaluation, the evaluation metrics will also contain bias. You are encouraged to improve the response variable creation process until you are confident in its ability to accurately train and evaluate your SDM for litoria fallax. For now, we will continue with this training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd81ab-0a5d-4d68-a504-2b34ca2d576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "filt = frog_data.occurrenceStatus == 1\n",
    "ax.scatter(frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude,\n",
    "           color = 'green', marker='.', alpha=0.5, label=target_species)\n",
    "ax.scatter(frog_data[~filt].decimalLongitude, frog_data[~filt].decimalLatitude,\n",
    "           color = 'yellow', marker='.', alpha=0.5, label=f\"Not {target_species}\")\n",
    "ax.legend()\n",
    "cx.add_basemap(ax, crs={'init':'epsg:4326'}, alpha=0.5)\n",
    "ax.set_title(f\"Training set for {region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd4236-b9a9-4622-9a59-2a3365ae9a01",
   "metadata": {},
   "source": [
    "## Predictor Variables\n",
    "\n",
    "Now that we have our response variable, it is time to gather the predictor variables from the TerraClimate dataset. For a more in-depth look at the TerraClimate dataset and how to query it, see the [TerraClimate supplementary notebook](./supplementary_notebooks/TerraClimate.ipynb)\n",
    "\n",
    "Also here is more info about the variables:\n",
    "https://planetarycomputer.microsoft.com/dataset/terraclimate\n",
    "\n",
    "### Accessing the TerraClimate Data\n",
    "\n",
    "To get the TerraClimate data, we write a function called `get_terraclimate`. This function will fetch all data intersecting with the bounding box and will calculate various metrics over the time dimension for each coordinate. In this example, we will take four metrics from four assets, namely the mean maximum monthly air temp (`tmax_mean`), mean minimum monthly air temp (`tmin_mean`), mean accumulated precipitation (`ppt_mean`) and mean soil moisture (`soil_mean`), all calculated over a five year timeframe from the start of 2015 to the end of 2019.\n",
    "\n",
    "To assist in visualisations, this function has an interpolation functionality which will allow the comparitively coarse temporal resolution of the terraclimate data to be mapped to a larger set of coordinates, creating an ($n$ x $m$) image. We will choose (512 x 512).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f4351-847a-4c66-a764-f9a0888b9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terraclimate(bbox, metrics, time_slice=None, assets=None, features=None, interp_dims=None, verbose=True):\n",
    "    \"\"\"Returns terraclimate metrics for a given area, allowing results to be interpolated onto a larger image.\n",
    "    \n",
    "    Attributes:\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    metrics -- Nested dictionary in the form {<metric_name>:{'fn':<metric_function>,'params':<metric_kwargs_dict>}, ... }\n",
    "    time_slice -- Tuple of datetime strings to select data between, e.g. ('2015-01-01','2019-12-31')\n",
    "    assets -- list of terraclimate assets to take\n",
    "    features -- list of asset metrics to take, specified by strings in the form '<asset_name>_<metric_name>'\n",
    "    interp_dims -- Tuple of dimensions (n, m) to interpolate results to\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    collection = pystac.read_file(\"https://planetarycomputer.microsoft.com/api/stac/v1/collections/terraclimate\")\n",
    "    asset = collection.assets[\"zarr-https\"]\n",
    "    store = fsspec.get_mapper(asset.href)\n",
    "    data = xr.open_zarr(store, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    \n",
    "    # Select datapoints that overlap region\n",
    "    if time_slice is not None:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat),time=slice(time_slice[0],time_slice[1]))\n",
    "    else:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat))\n",
    "    if assets is not None:\n",
    "        data = data[assets]\n",
    "    print('Loading data') if verbose else None\n",
    "    data = data.rename(lat='y', lon='x').to_array().compute()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    combined_values = []\n",
    "    combined_bands = []\n",
    "    for name, metric in metrics.items():\n",
    "        print(f'Calculating {name}') if verbose else None\n",
    "        sum_data = xr.apply_ufunc(\n",
    "            metric['fn'], data, input_core_dims=[[\"time\"]], kwargs=metric['params'], dask = 'allowed', vectorize = True\n",
    "        ).rename(variable='band')\n",
    "        xcoords = sum_data.x\n",
    "        ycoords = sum_data.y\n",
    "        dims = sum_data.dims\n",
    "        combined_values.append(sum_data.values)\n",
    "        for band in sum_data.band.values:\n",
    "            combined_bands.append(band+'_'+name)\n",
    "        \n",
    "    # Combine metrics\n",
    "    combined_values = np.concatenate(\n",
    "        combined_values,\n",
    "        axis=0\n",
    "    )\n",
    "    combined_data = xr.DataArray(\n",
    "        data=combined_values,\n",
    "        dims=dims,\n",
    "        coords=dict(\n",
    "            band=combined_bands,\n",
    "            y=ycoords,\n",
    "            x=xcoords\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    # Take relevant bands:\n",
    "    combined_data = combined_data.sel(band=features)\n",
    "    \n",
    "    if interp_dims is not None:\n",
    "        print(f'Interpolating image') if verbose else None\n",
    "        interp_coords = (np.linspace(bbox[0], bbox[2], interp_dims[0]), np.linspace(bbox[1], bbox[3], interp_dims[1]))\n",
    "        combined_data = combined_data.interp(x=interp_coords[0], y=interp_coords[1], method='nearest', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e65acf-b700-43a3-9c39-d0f40a87e616",
   "metadata": {},
   "source": [
    "Below, we define the products to take from TerraClimate in `assets` and the metrics to calculate from them in `tc_metrics`. Each metric is applied to each asset, so to pick the desired asset/metric pairs we define a list of strings in the form '\\<asset\\>_\\<metric\\>' in `features`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7da9ea-10ed-418e-a803-ea4db74e0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to measure over time dimension\n",
    "tc_metrics = {\n",
    "    'mean':{\n",
    "        'fn':np.nanmean,\n",
    "        'params':{}\n",
    "    },\n",
    "    'min':{\n",
    "        'fn':np.nanmin,\n",
    "        'params':{}\n",
    "    },\n",
    "    'max':{\n",
    "        'fn':np.nanmax,\n",
    "        'params':{}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Date range to take\n",
    "time_slice = ('2015-01-01','2019-12-31')\n",
    "\n",
    "# Measurements to take\n",
    "assets=['tmax', 'tmin', 'ppt', 'soil']\n",
    "\n",
    "# Features to take, in form '<asset>_<metric>'\n",
    "features=['tmax_mean', 'tmin_mean', 'ppt_mean', 'soil_mean']\n",
    "\n",
    "# Interpolate values to a 512x512 image\n",
    "interp_dims = (512, 512)\n",
    "\n",
    "weather_data = get_terraclimate(bbox, tc_metrics, time_slice=time_slice, assets=assets, features=features, interp_dims=interp_dims)\n",
    "display(weather_data.band.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c46b7c-5a21-4311-bd0c-265eae7e7a03",
   "metadata": {},
   "source": [
    "### Visualising the TerraClimate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a3347-a22d-4369-ae28-131326f72bc5",
   "metadata": {},
   "source": [
    "The spatial distribution of the four variables are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d8700-710d-4f39-8d7f-661fd29f583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 2\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(13, 7), sharex=True, sharey=True)\n",
    "\n",
    "bands = weather_data.band.values\n",
    "filt = frog_data.occurrenceStatus == 1\n",
    "cmaps = [\"cool\", \"cool\", \"Blues\", \"BrBG\"]\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    xr.plot.imshow(weather_data[i], 'x', 'y', cmap=cmaps[i], ax=ax[i//ncol, i%ncol]) \n",
    "    ax[i//ncol, i%ncol].set_title(bands[i])\n",
    "    ax[i//ncol, i%ncol].scatter(frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude,\n",
    "                                color = 'yellow', marker='.', alpha=0.5, label=target_species if i==0 else '')\n",
    "\n",
    "fig.suptitle(\"Spatial distribution of Terraclimate variables\", fontsize=20)\n",
    "fig.legend(loc=(0.85, 0.933))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4e3c2-3971-4f04-9ca7-19e059948517",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd00439-c77f-4aaf-9cf7-274457de8b2d",
   "metadata": {},
   "source": [
    "The frequency distribution of each variable is displayed below. There is some skewness present in a few variables, so you might want to address this when training your own model. Depending on the type of model you decide to train, some of the variables might require normalisation, standardisation, or transformation. For now, we will proceed with the variables as they come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e9aaf-6b2c-4587-8b32-64e739591615",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 2\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(13, 7))\n",
    "\n",
    "bands = weather_data.band.values\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    xr.plot.hist(weather_data[i], ax=ax[i//ncol, i%ncol])\n",
    "\n",
    "fig.suptitle(\"Frequency distribution of TerraClimate variables\",  fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0774bc5-4dff-4812-a1c6-70768abca0c9",
   "metadata": {},
   "source": [
    "### Joining Pretictors to the Response Variable\n",
    "\n",
    "Now that we have read in our predictor variables, we need to join them onto the response variable of frogs. To do this, we loop through the frog occurrence data and assign each frog occurrence the closest predictor pixel value from each of the predictor variables based on the geo-coordinates. The `sel` method of the xarray dataarray comes in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397daf8-cb09-4a57-8317-e3a7d13a2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_frogs(frogs, data):\n",
    "    \"\"\"Collects the data for each frog location and joins it onto the frog data \n",
    "\n",
    "    Arguments:\n",
    "    frogs -- dataframe containing the response variable along with [\"decimalLongitude\", \"decimalLatitude\", \"key\"]\n",
    "    data -- xarray dataarray of features, indexed with geocoordinates\n",
    "    \"\"\"\n",
    "    return frogs.merge(\n",
    "        (\n",
    "            data\n",
    "            .rename('data')\n",
    "            .sel(\n",
    "                x=xr.DataArray(frog_data.decimalLongitude, dims=\"key\", coords={\"key\": frog_data.key}), \n",
    "                y=xr.DataArray(frog_data.decimalLatitude, dims=\"key\", coords={\"key\": frog_data.key}),\n",
    "                method=\"nearest\"\n",
    "            )\n",
    "            .to_dataframe()\n",
    "            .assign(val = lambda x: x.iloc[:, -1])\n",
    "            [['val']]\n",
    "            .reset_index()\n",
    "            .drop_duplicates()\n",
    "            .pivot(index=\"key\", columns=\"band\", values=\"val\")\n",
    "            .reset_index()\n",
    "        ),\n",
    "        on = ['key'],\n",
    "        how = 'inner'\n",
    "    )\n",
    "    \n",
    "model_data = join_frogs(frog_data, weather_data)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb154fe-e72c-4e0f-b4ea-5a20384de3f5",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "### Model Training\n",
    "\n",
    "Now that we have the data in a format appropriate for machine learning, we can begin training a model. For this demonstration notebook, we will use a basic logistic regression model from the [scikit-learn](https://scikit-learn.org/stable/) library. This library offers a wide range of other models, each with the capacity for extensive parameter tuning and customisation capabilities.\n",
    "\n",
    "Scikit-learn models require separation of predictor variables and the response variable. We store the predictor variables in dataframe `X` and the response in the array `y`. We must make sure to drop the response variable from `X`, otherwise the model will have the answers! It also doesn't make sense to use latitude and longitude as predictor variables in such a confined area, so we drop those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dd94e-ba93-4667-897b-3923d3712567",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = LogisticRegression()\n",
    "# Separate the predictor variables from the response\n",
    "X = (\n",
    "    model_data\n",
    "    .drop(['gbifID', 'eventDate', 'decimalLatitude', 'decimalLongitude', 'species',\n",
    "       'country', 'continent', 'stateProvince', 'occurrenceStatus', 'key'], 1)\n",
    ")\n",
    "y = model_data.occurrenceStatus.astype(int)\n",
    "\n",
    "# Fit model\n",
    "full_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565957c9-cba5-4948-84b6-c8f74f4cf598",
   "metadata": {},
   "source": [
    "### Model Prediction\n",
    "\n",
    "#### Predict Training Set\n",
    "\n",
    "Logistic regression is a machine learning model that estimates the probability of a binary response variable. In our case, the model will output the probability of a frog being present at a given location. To obtain the predictions for our training set, we simply use the `predict` method on our trained model. We will evaluate these predictions in the evaluation section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b014512-659b-4f72-9102-b2b31c51bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = full_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51835e-6061-4db0-9ad1-3a2510c6b271",
   "metadata": {},
   "source": [
    "#### Predict Entire Region\n",
    "\n",
    "For a species distribution model to be effective, it must also be capable of performing predictions over the entire region, not just the points in our training set. To do this, we will define another function called `predict_frogs` that will take our interpolated predictor variable image in, along with our logistic regression model, and output the probabilities for each pixel in the region. We will visualise these predictions in a heatmap in the results section of this notebook.\n",
    "\n",
    "This function will be used later to predict the test regions for the challenge. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a306561-6f2b-4f0d-9ede-b98b702ac226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frogs(predictor_image, model):\n",
    "    \"\"\"Returns a (1, n, m) xarray where each pixel value corresponds to the probability of a frog occurrence.\n",
    "    \n",
    "    Takes in the multi-band image outputted by the `create_predictor_image` function as well as the\n",
    "    trained model and returns the predictions for each pixel value. Firstly, the $x$ and $y$ indexes\n",
    "    in the predictor image are stacked into one multi-index $z=(x, y)$ to produce an $k\\times n$\n",
    "    array, which is the format required to feed into our logistic regression model. Then, the array\n",
    "    is fed into the model, returning the model's predictions for the frog likelihood at each pixel. \n",
    "    The predicted probabilities are then indexed by the same multi-index $z$ as before, which allows \n",
    "    the array to be unstacked and returned as a one-band image, ready for plotting.\n",
    "\n",
    "    Arguments:\n",
    "    predictor_image -- (K, n, m) xarray, where K is the number of predictor variables.\n",
    "    model -- sklearn model with K predictor variables.\n",
    "    \"\"\"\n",
    "    # Stack up pixels so they are in the appropriate format for the model\n",
    "    predictor_image = predictor_image.stack(z=(\"y\", \"x\")).transpose()\n",
    "    # Reorder variables to be in same order as model\n",
    "    predictor_image = predictor_image.sel(band=model.feature_names_in_)\n",
    "    # Location of null values so that we can skip them (prediction model will break if nulls are present)\n",
    "    null_pixels = (np.sum(predictor_image.isnull(), axis=-1) > 0)\n",
    "    # Empty probabilities array\n",
    "    probabilities = np.zeros((len(null_pixels), 2))\n",
    "    # Calculate probability for each non-null pixel point\n",
    "    probabilities[~null_pixels] = model.predict_proba(\n",
    "        predictor_image[~null_pixels]\n",
    "    )\n",
    "    # Set null pixels to a probability of null\n",
    "    probabilities[null_pixels] = np.array([np.nan, np.nan])\n",
    "    # Just take probability of frog (class=1)\n",
    "    probabilities = probabilities[:,1]\n",
    "    # Add the coordinates to the probabilities, saving them in an xarray\n",
    "    resultant_image = xr.DataArray(\n",
    "        data=probabilities,\n",
    "        dims=['z'],\n",
    "        coords=dict(\n",
    "            z=predictor_image.z\n",
    "        )\n",
    "    )\n",
    "    # Unstack the image\n",
    "    resultant_image = resultant_image.unstack()\n",
    "    return resultant_image\n",
    "\n",
    "# Calculate probability for each pixel point \n",
    "resultant_image = predict_frogs(weather_data, full_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca09d5-b7d1-42cf-80cb-66fc23225974",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Now that we have trained our model and made some predictions, all that is left is to evaluate it. We will do this by first visualising the output of the model with a probability heatmap. Then, we will evaluate both its in-sample and out-of-sample performance using the training set we have generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08badfa5-98bd-4962-b39a-a19966babfd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### In-Sample Evaluation\n",
    "\n",
    "In the last section, we made our predicitons for the training set and stored them in the `predictions` variable. We can now calculate some performance metrics to guage the effectiveness of the model. It must be stressed that this is the in-sample performance - the performance on the training set. Hence, the values will tend to overestimate its performance. Additionally, the training set itself is biased and this notebook only took naive approaches to address this. The model evaluation metrics are only as good as the data used to evaluate it, so the metrics themselves will also be biased. Thus, these metrics are NOT truly indicative of this model's performance. \n",
    "\n",
    "In this example, we will use `f1_score` and `accuracy_score` from Scikit-learn. Scikit-learn provides many other metrics that can be used for evaluation. You can even code your own if you think it will assist you in evaluating your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db621c-d83f-4ffc-ba7e-8579a79da9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score: {np.mean(f1_score(y, predictions)).round(2)}\")\n",
    "print(f\"Accuracy: {np.mean(accuracy_score(y, predictions)).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ea862-0e9f-469f-8d18-f790cd738304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(full_model, X, y, display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Model Level 1: Logistic\\nRegression Model In-Sample Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47abbe6d-665d-4469-9c33-3eeb623159d4",
   "metadata": {},
   "source": [
    "From above, we see that the model is able to achieve an ok F1 score and accuracy. From the confusion matrix, we can see that our model seems to confuse absent points with present points aka false positives, as shown in the top right corner. There may be many reasons for this, and a great way of understanding what might be causing the model's high false positive rate is to visualise its performance over the training region. We do this by plotting a probabilty heatmap in the section below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c1c74-e309-4fb5-9063-e680651f3bc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Probability Heatmap\n",
    "\n",
    "To create the probability heatmap, we write a function called `plot_heatmap`. This function will take in the model predictions from the entire region as stored in the `resultant_image` variable, and visualise these probabilities as a heatmap. In addition to the heatmap, we will also plot the actual map of the area in question, and the binary classification regions of the probability heatmap. The latter is simply a binary mask of the probability heatmap, 1 where the probability is greater than 0.5 and 0 elsewhere. \n",
    "\n",
    "To help visualise the effectiveness of our model, we plot the target species occurrences over top of each image. This can give us an idea of where our model is doing well, and where it is doing poorly. Particularly, we are interested in the high false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb12b7-395d-4741-8ed6-0487f6d611d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(resultant_image, frog_data, title, crs = {'init':'epsg:4326'}):\n",
    "    \"\"\"Plots a real map, probability heatmap, and model classification regions for the probability image from our model.\n",
    "\n",
    "    Arguments:\n",
    "    resultant_image -- (1, n, m) xarray of probabilities output from the model\n",
    "    frog_data -- Dataframe of frog occurrences, indicated with a 1 in the occurrenceStatus column. \n",
    "                 Must contain [\"occurrenceStatus\", \"decimalLongitude\", \"decimalLatitude\"]\n",
    "    title -- string that will be displayed as the figure title\n",
    "    crs -- coordinate reference system for plotting the real map. Defaults to EPSG:4326.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (20, 10), sharex=True, sharey=True)\n",
    "    extent = [resultant_image.x.min(),resultant_image.x.max(),resultant_image.y.min(),resultant_image.y.max()]\n",
    "    cmap = 'PiYG'\n",
    "\n",
    "    # Plot real map\n",
    "    ax[0].scatter(x=[extent[0], extent[1]], y=[extent[2], extent[3]], alpha=0)\n",
    "    cx.add_basemap(ax[0], crs=crs)\n",
    "    ax[0].set_title('Real map')\n",
    "    \n",
    "    # Plot heatmap from model\n",
    "    heatmap = resultant_image.plot.imshow(\n",
    "        x='x', y='y', ax=ax[1], cmap=cmap, vmin=0, vmax=1, interpolation='none', add_colorbar=False\n",
    "    )\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_title('Model Probability Heatmap')\n",
    "\n",
    "    # Plot binary classification from model\n",
    "    regions = xr.where(resultant_image.isnull(), np.nan, resultant_image>0.5).plot.imshow(\n",
    "            x='x', y='y', ax=ax[2], cmap=cmap, vmin=0, vmax=1, interpolation='none', add_colorbar=False\n",
    "    )\n",
    "    ax[2].set_aspect('equal')\n",
    "    ax[2].set_title('Model Classification Regions')\n",
    "\n",
    "    # Plot real frogs\n",
    "    for i, axis in enumerate(ax):\n",
    "        filt = frog_data.occurrenceStatus == 1\n",
    "        axis.scatter(\n",
    "            frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude, \n",
    "            color = 'dodgerblue', marker='.', alpha=0.5, label='Target Species' if i==0 else ''\n",
    "        )\n",
    "\n",
    "    fig.colorbar(heatmap, ax=ax, location = 'bottom', aspect=40)\n",
    "    fig.legend(loc = (0.9, 0.9))\n",
    "    fig.suptitle(title, x=0.5, y=0.9, fontsize=20)\n",
    "    \n",
    "plot_heatmap(resultant_image, frog_data, f\"Logistic Regression Model Results - {region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab57d7-29c2-4cf9-b6cf-644ff6504a7d",
   "metadata": {},
   "source": [
    "From the plots above, we can see that the model does a pretty good job of mapping where litoria fallax is. However, our performance metrics before suggested otherwise. The main limitation of the evaluation metrics comes from the pseudo absence species, crinia signifera, sharing much of the same habitat as litoria fallax. This paired with the relatively coarse spatial resolution of TerraClimate makes distinguising close habitats difficult. This explains the high rate of false positives, as there are many frog absence points within the green classification region. \n",
    "\n",
    "There are many ways you might go about addressing this issue. Perhaps choosing a species that does not closely share the same habitat as litoria fallax. Alternatively, a greater variety of spatial sampling could also resolve this issue, i.e. picking extra regions where only litoria fallax exists and some where only other species exist. Another option is to abandon the pseudo-absence approach entirely and develop a unique way of sampling for absence points. Ultimately, you might think it is worthwhile improving the training set to make your evaluation metrics a little more representative of the SDM performance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d77515-bbdc-48aa-b21f-5dd6aff7a52c",
   "metadata": {},
   "source": [
    "#### Out-of-Sample Evaluation\n",
    "\n",
    "When evaluating a machine learning model, it is essential to correctly and fairly evaluate the model's ability to generalise. This is because models have a tendancy to overfit the dataset they are trained on. To estimate the out-of-sample performance, we will use k-fold cross-validation. This technique involves splitting the training dataset into folds, in this case we will use 10. Each iteration, the model is trained on all but one of the folds, which is reserved for testing. This is repeated until all folds have been left out once. At the end of the process, we will have 10 metrics which can be averaged, giving a more reliable and valid measure of model performance. \n",
    "\n",
    "Scikit-learn has built-in functions that can assist in k-fold cross validation. In particular, we will use `StratifiedKFold` to split our data into folds, ensuring there is always a balanced number of frogs and non-frogs in each fold.\n",
    "\n",
    "Again, these metrics are derived from a biased sample, so be careful what you infer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e992d-08cd-4ce6-9330-852263bd0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = LogisticRegression()\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=420, shuffle=True)\n",
    "metrics = {'F1': f1_score, 'Accuracy': accuracy_score}\n",
    "results = {'predicted':[], 'actual':[]}\n",
    "scores = {'F1': [], 'Accuracy': []}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    # Split the dataset\n",
    "    print(f\"Fold {i+1} of {n_folds}\")\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model with the training set\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = cv_model.predict(X_test)\n",
    "    \n",
    "    for metric, fn in metrics.items():\n",
    "        scores[metric].append(fn(y_test, predictions))\n",
    "        \n",
    "    results['predicted'].extend(predictions)\n",
    "    results['actual'].extend(list(y_test))\n",
    "        \n",
    "print(f'\\nMetrics averaged over {n_folds} trials:')\n",
    "for metric, result in scores.items():\n",
    "    print(f\"{metric}: {np.mean(result).round(2)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239a36d-4d40-4ce8-ace4-ccad12bc0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_predictions(results['actual'], results['predicted'], display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Model Level 1: Logistic Regression Model\\n10-fold Cross Validation Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddcdfe-309f-43e5-862a-24497d12450e",
   "metadata": {},
   "source": [
    "The results from the 10-fold cross validation are similar than the in-sample metrics. This is a good sign as it shows that we haven't overfit our model. We see similar behavour in the higher rate of false positives that we saw in the in-sample performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca134a4-7445-4097-ad62-574453c00c21",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Once you are happy with your model, there will come a time to make a submission to the challenge. To make a submission, you will need to use your model to make predictions about the presence of litoria fallax for a set of test coordinates we have provided. The coordinates are found in the 'challenge_1_submission_template.csv' file, and the list of bounding boxes where the points were sampled from can be found separately in the 'challenge_1_test_regions.txt' file. We recommend looping through the regions identified in that file, pulling the TerraClimate data for that region, and extracting the features for each point in the 'test_1_occurrences.csv' file within that regions bounding box. This will minimise the computational requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acebfca-8e59-4fbb-b87e-9c61406d9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in test coordinates\n",
    "test_file = pd.read_csv('../raw_data/challenge_1_submission_template.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f923285-32ad-4dfb-8595-1c80e3aebf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test regions\n",
    "test_1_regions = []\n",
    "with open('../raw_data/challenge_1_test_regions.txt', 'r') as file: \n",
    "    for i, line in enumerate(file):\n",
    "        if i > 0:\n",
    "            test_1_regions.append(eval(\"(\"+line+\")\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dd01f-4802-44d8-bd30-7ca18aa51cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in regions and save as list of dictionaries.\n",
    "test_regions = [{'title':i, 'bbox':bbox} for i, bbox in enumerate(test_1_regions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a909537b-fc16-40d5-bd2e-213e47826091",
   "metadata": {},
   "source": [
    "Note: with the TerraClimate parameters we have set, some areas of each region contain nulls. If this is the case, the prediction will return a null, which evaluates to false when we create the binary mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c645d-9cf7-4aaa-a93f-a3d1f16fda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictor data for each region and get predictor image\n",
    "for region in test_regions:\n",
    "    region['coords'] = filter_bbox(test_file[['id', 'decimalLongitude', 'decimalLatitude']], region['bbox'])\n",
    "    region['predictors'] = get_terraclimate(region['bbox'], tc_metrics, time_slice=time_slice, assets=assets, features=features)\n",
    "    region['result'] = predict_frogs(region['predictors'], full_model) > 0.5\n",
    "    \n",
    "    region['result'].plot.imshow(x='x', y='y', vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bec83a-6b6b-40b9-b869-87dce4275b80",
   "metadata": {},
   "source": [
    "We can now use these classification regions to assign predictions for each of the coordinates specified in the test file. We do this in a similar way to the `join_frogs` function we defined earlier, except in this case we are joining a prediction to each coordinate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe031cf-400d-40e8-adc1-d2df9e8b4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "\n",
    "for region in test_regions:\n",
    "    preds = (\n",
    "        region['result'].rename('occurrenceStatus')\n",
    "        .sel(\n",
    "            x=xr.DataArray(region['coords'].decimalLongitude, dims=\"id\", coords={\"id\": region['coords'].id}), \n",
    "            y=xr.DataArray(region['coords'].decimalLatitude, dims=\"id\", coords={\"id\": region['coords'].id}),\n",
    "            method=\"nearest\"\n",
    "        )\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        .rename(columns={'x':'decimalLongitude', 'y':'decimalLatitude'})\n",
    "    )\n",
    "    predictions = predictions.append(preds)\n",
    "            \n",
    "submission = (    \n",
    "    predictions.merge(\n",
    "        test_file, \n",
    "        on=['decimalLongitude', 'decimalLatitude'], \n",
    "        how='left', suffixes = ('', '_'))\n",
    "    [test_file.columns]\n",
    "    .fillna(0)\n",
    "    .astype({col:'int' for col in test_file.columns[3::]})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b624948-932e-4b06-a23b-72a13767a705",
   "metadata": {},
   "source": [
    "What we are left with is a submission file with three columns: decimalLatitude, decimalLongitude, and occurrenceStatus. This is the file you will submit to the EY Data Science Challenge platform to receive your score on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60ccee-1fa5-4b35-a6c8-069d9cea33f0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(submission)\n",
    "\n",
    "# Save to output folder\n",
    "submission.to_csv('../submission_data/challenge_1_submission_benchmark.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41938b59-c2be-454e-be3a-80251330aa62",
   "metadata": {},
   "source": [
    "### Get Frogging!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec962f-89f9-465e-9269-73374840dcb8",
   "metadata": {},
   "source": [
    "Now that you have witnessed a basic approach to model training, its time to try your own approach! Feel free to modify any of the functions presented in this notebook. A good start might be to try running this notebook on a region different to Greater Sydney, or even on multiple regions.\n",
    "\n",
    "Be sure to address some of the assumptions made here, particularly ways to address the sampling bias in the dataset. Our pseudo-absence method was just one idea, you may want to persue another. Another important issue to consider is that of class imbalance. In this notebook, we simply down-sampled the non-target species to match the number of target species. This may not be ideal, as an isolated frog occurrence may be lost while clusters of occurrences are more likely to persist. Perhaps a method of sampling only from clustered occurrences would address class imbalance while also helping to offset the sampling bias. Just a thought! You might even decide on a completely different training set, such as classifying regions rather than points. Do whatever you think will create the best model for predicting the frog habitat of the species of interest. Happy frogging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3be98d-be06-44b2-b459-33cde907f64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022DSC",
   "language": "python",
   "name": "conda-env-2022DSC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
